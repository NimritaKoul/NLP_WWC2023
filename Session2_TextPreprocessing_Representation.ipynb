{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f92677e",
   "metadata": {
    "id": "3f92677e"
   },
   "source": [
    "# Natural Language Processing using Python\n",
    "\n",
    "<b> This  4 hour workshop will introduce the audience to the field of Natural Language Processing,  we will cover the fundamental tasks in NLP and walk through the Python code for some of the important steps in an NLP project.</b>\n",
    "\n",
    "<b> Author:  Dr. Nimrita Koul, Associate Professor, Machine Learning</b><br>\n",
    "<b> Who this talk is suitable for:  Data analysts, students and anyone interested in using Natural Language Processing</b><br>\n",
    "<b>Prerequisites:  Python Programming, basic familiarity with concepts in data science and machine learning</b><br>\n",
    "<b> Duration:  4 Sessions of 1 hour each</b><br>\n",
    "<b>Time:  Starting 9th March 2023, Every Thursday,  8.00 pm to 9.00 pm Indian Standard Time</b><br>\n",
    "<b> Github URLs:</b><br>\n",
    "URL of Session 1 Jupyter Notebook: https://github.com/NimritaKoul/NLP_WWC2023/blob/main/Session1_Introduction%20to%20Natural%20Language%20Processing.ipynb\n",
    "\n",
    "URL of Session 2 Jupyter Notebook:\n",
    "https://github.com/NimritaKoul/NLP_WWC2023/blob/main/Session2_Final.ipynb\n",
    "\n",
    "\n",
    "### Contents: \n",
    "\n",
    "#### Session 1:\n",
    "1. Introduction to Natural Language Processing, components, task, applications. \n",
    "2. Python Tools and Libraries for NLP - with focus on NLTK and SpaCy \n",
    "\n",
    "#### Session 2:\n",
    "<span style=\"color:Blue\">    \n",
    "1. Text Preprocessing - normalization, tokenization, stopword removal, case conversion, stemming, lemmatization, POS tagging<br>\n",
    "2. Text Representation - Bag of word models, TF-IDF, Word Embeddings\n",
    "</span>\n",
    "\n",
    "#### Session 3:\n",
    "1. Text Classification - Text classification models Naive Bayes, Decision Tree, RNN\n",
    "2. Transformers\n",
    "\n",
    "#### Session 4 :  Case Study\n",
    "1. Sentiment Analysis\n",
    "2. Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e73242",
   "metadata": {
    "id": "c3e73242"
   },
   "source": [
    "### Recap of session1 :\n",
    "\n",
    "#### Natural Language Processing (NLP) is a branch of AI that aims at building computer systems that can understand natural language and respond in a natural language.\n",
    "\n",
    "<b>Human language is filled with ambiguities</b> These ambiguities in natural language make task of understanding natural language very hard. A number of NLP tasks are required to convert the text data into a meaningful form. \n",
    "\n",
    "#### NLP Tasks\n",
    "\n",
    "1. Text Preprocessing : Tokenization, Normalization - Case conversion, stop words removal, stemming, lemmatization\n",
    "2. Representing text in numerical vectors: Vector Embedding\n",
    "3. Part of speech tagging \n",
    "4. Identifying relationships among words\n",
    "5. Word sense disambiguation\n",
    "6. Named entity recognition  \n",
    "7. Co-reference resolution \n",
    "8. Sentiment analysis\n",
    "9. Text Classification\n",
    "10. Speech recognition \n",
    "11. Recognizing Textual Entailment\n",
    "12. Natural language generation \n",
    "13. Language Modelling\n",
    "\n",
    "#### NLP use cases\n",
    "\n",
    "1. Spam detection\n",
    "2. Machine translation\n",
    "3. Conversational AI\n",
    "4. Text summarization\n",
    "5. Auto correct and Auto complete\n",
    "6. Semantic search\n",
    "7. Health Care\n",
    "8. Finance\n",
    "9. HR\n",
    "10. Market Intelligence etc. \n",
    "\n",
    "#### Python libraries for NLP : NLTK, Spacy, TextBlob, Gensim, PolyGlot, Sklearn\n",
    "\n",
    "\n",
    "#### NLTK  (www.nltk.org)\n",
    "- Free and opensource library for NLP research and development in multiple languages.\n",
    "NLTK comes with many corpora, toy grammars, trained models, etc. (https://www.nltk.org/nltk_data/)\n",
    "\n",
    "NLTK Installation:\n",
    "using pip:\n",
    "<code> pip install nltk</code>\n",
    "\n",
    "For Ananconda using conda:\n",
    "<code> conda install nltk</code>\n",
    "\n",
    "\n",
    "#### Spacy (https://spacy.io/)\n",
    "Spacy is a free, opensource and industrial-strength library for NLP in Python. It provides a huge ecosystem of plugins and components, enables you to build custom components and workflows.\n",
    "\n",
    "Download and Install (https://spacy.io/usage)\n",
    "Using pip: \n",
    "<code>\n",
    "pip install -U pip setuptools wheel\n",
    "pip install spacy\n",
    "</code>\n",
    "\n",
    "Using conda:\n",
    "<code>conda install -c conda-forge spacy</code>\n",
    "\n",
    "After installing spacy, we need to download the suitable NLP pipeline of a language we usually work with (English in our case):\n",
    "\n",
    "<code>python -m spacy download en_core_web_sm<code>\n",
    "\n",
    "spaCy’s trained pipelines can be installed as Python packages. Trained pipelines can be installed from a download URL or a local directory, manually or via pip. Their data can be located anywhere on your file system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1db050",
   "metadata": {
    "id": "ad1db050"
   },
   "source": [
    "### References for Text Preprocessing\n",
    "1. https://www.kaggle.com/datasets/datatattle/covid-19-nlp-text-classification?resource=download\n",
    "2. https://www.kaggle.com/code/sudalairajkumar/getting-started-with-text-preprocessing\n",
    "3. https://github.com/JasonKessler/scattertext\n",
    "3. https://www.kaggle.com/code/pierremegret/gensim-word2vec-tutorial\n",
    "4. https://homepages.inf.ed.ac.uk/sgwater/math_tutorials.html\n",
    "5. https://radimrehurek.com/gensim/models/word2vec.html\n",
    "6. https://dataaspirant.com/nlp-text-preprocessing-techniques-implementation-python/\n",
    "7. https://www.enjoyalgorithms.com/blog/text-data-pre-processing-techniques-in-ml\n",
    "8. https://www.enjoyalgorithms.com/blog/word-vector-encoding-in-nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a37ca2",
   "metadata": {
    "id": "79a37ca2"
   },
   "source": [
    "# Session 2 : 16 March 2023\n",
    "\n",
    "### On the agenda today:\n",
    "\n",
    "1. Text Preprocessing\n",
    "2. Text Representation\n",
    "\n",
    "### Text Preprocessing\n",
    "\n",
    "Text preprocessing involves a number of tasks that transform text into a clean format, ready to be used for further processing or to be fed to an ML model. Depending upon the specific text data and the specific NLP task, different types of preprocessing may be required. \n",
    "\n",
    "Common pre-processing tasks involve: \n",
    "\n",
    "- Text Normalization - Conversion of text to canonical representation. Conversion to lower case\n",
    "- Removing stopwords, punctuations, special words or text pieces e.g. hash tags, URLs, emojis\n",
    "- Stemming\n",
    "- Lemmatization\n",
    "- Spelling correction\n",
    "- Exploratory analysis through plotting\n",
    "\n",
    "Libraries like NLTK, SpaCy provide built in functionality for text-preprocessing.\n",
    "\n",
    "#### Benefits of  Text Preprocessing\n",
    "-  Dimensionality Reduction: In the vector embedding space, a text document is represented a multidimensional vector. Every word in this document is one of the dimensions. Dimensionality reduction has the well known advantage of navigating the curse of dimensionality and improving the performance of tasks like document classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ccba99",
   "metadata": {
    "id": "d9ccba99"
   },
   "source": [
    "### Text Pre-processing : Text Data Cleaning and Preparation Steps\n",
    "### Dataset URL:  Corona Virus NLP Tweets data set\n",
    "##### https://www.kaggle.com/datasets/datatattle/covid-19-nlp-text-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a3777a2",
   "metadata": {
    "id": "4a3777a2",
    "outputId": "f68732b9-4ca3-4be6-d00e-187450130f8e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('Corona_NLP_train.csv',  encoding='latin-1')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5bd5276",
   "metadata": {
    "id": "c5bd5276",
    "outputId": "6fbdb739-e7d2-4172-b69a-9bd15cdc55b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41157, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4d52706",
   "metadata": {
    "id": "d4d52706",
    "outputId": "ba834405-e4a3-463a-e910-b52aad44156b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UserName', 'ScreenName', 'Location', 'TweetAt', 'OriginalTweet',\n",
       "       'Sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9acad6",
   "metadata": {
    "id": "1d9acad6",
    "outputId": "478353f7-3b5d-4200-aee9-207c14cc5a02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserName            0\n",
       "ScreenName          0\n",
       "Location         8590\n",
       "TweetAt             0\n",
       "OriginalTweet       0\n",
       "Sentiment           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "393b6e8b",
   "metadata": {
    "id": "393b6e8b"
   },
   "outputs": [],
   "source": [
    "train_data = train_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c1a8f77",
   "metadata": {
    "id": "6c1a8f77",
    "outputId": "98d00b05-3a93-4d58-8c36-4e6a2b8067e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32567, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16021e8d",
   "metadata": {
    "id": "16021e8d",
    "outputId": "f1dd0d36-0764-4d08-98b6-76159cce796e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OriginalTweet', 'Sentiment'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.drop(['UserName', 'ScreenName', 'Location', 'TweetAt'], axis = 1)\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50115ba",
   "metadata": {
    "id": "b50115ba"
   },
   "source": [
    "#### We will do data cleaning and pre-processing on the OriginalTweet Column of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d0625aa",
   "metadata": {
    "id": "2d0625aa",
    "outputId": "c5a597b6-873d-492a-9c7d-cadb772d3c9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@menyrbie @phil_gahan @chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coronavirus australia: woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>as news of the regionâs first confirmed covid...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cashier at grocery store was sharing his insig...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet Sentiment\n",
       "0  @menyrbie @phil_gahan @chrisitv https://t.co/i...   Neutral\n",
       "1  advice talk to your neighbours family to excha...  Positive\n",
       "2  coronavirus australia: woolworths to give elde...  Positive\n",
       "5  as news of the regionâs first confirmed covid...  Positive\n",
       "6  cashier at grocery store was sharing his insig...  Positive"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. Case Conversion to Lower Case\n",
    "train_data['OriginalTweet'] = train_data['OriginalTweet'].str.lower()\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfbf2d8d",
   "metadata": {
    "id": "cfbf2d8d",
    "outputId": "ed444515-6c1c-45b2-a826-2d2ba9603f14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OriginalTweet', 'Sentiment'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a5085db",
   "metadata": {
    "id": "3a5085db",
    "outputId": "9d6fdcd8-90b9-4a3f-fbb7-be7004b34adc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        @menyrbie @phil_gahan @chrisitv https://t.co/i...\n",
       "1        advice talk neighbours family exchange phone n...\n",
       "2        coronavirus australia: woolworths give elderly...\n",
       "5        news regionâs first confirmed covid-19 case c...\n",
       "6        cashier grocery store sharing insights #covid_...\n",
       "                               ...                        \n",
       "41147    yâall really shitting much home?? #covid19 #c...\n",
       "41149    still shocked number #toronto supermarket empl...\n",
       "41150    never weâd situation &amp; world going superm...\n",
       "41152    airline pilots offering stock supermarket shel...\n",
       "41156    @tartiicat well new/used rift going $700.00 am...\n",
       "Name: OriginalTweet, Length: 32567, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove stop words and punctuation marks\n",
    "#https://stackoverflow.com/questions/29523254/python-remove-stop-words-from-pandas-dataframe\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stopwordsandpunct = stop_words + list(string.punctuation)\n",
    "\n",
    "train_data['OriginalTweet'] = train_data['OriginalTweet'].apply(lambda w:' '.join(w for w in w.split() if w not in stopwordsandpunct))\n",
    "train_data['OriginalTweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29bf4e1d",
   "metadata": {
    "id": "29bf4e1d",
    "outputId": "26cd73b2-5763-4fbe-e9a1-24f285f775b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   @menyrbie @phil_gahan @chrisitv   \n",
       "1    advice talk neighbours family exchange phone n...\n",
       "2    coronavirus australia: woolworths give elderly...\n",
       "5    news regionâs first confirmed covid-19 case c...\n",
       "6    cashier grocery store sharing insights #covid_...\n",
       "Name: OriginalTweet, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove URLs from all the tweets\n",
    "import re\n",
    "def remove_url(tweet):\n",
    "    tweet = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', tweet)\n",
    "    return tweet\n",
    "\n",
    "train_data['OriginalTweet'] = train_data['OriginalTweet'].apply(remove_url)\n",
    "train_data['OriginalTweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "438ef091",
   "metadata": {
    "id": "438ef091",
    "outputId": "a1daa321-ae9c-4668-fc9c-4993a02490d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                     \n",
       "1    advice talk neighbours family exchange phone n...\n",
       "2    coronavirus australia: woolworths give elderly...\n",
       "5    news regionâs first confirmed covid-19 case c...\n",
       "6    cashier grocery store sharing insights  prove ...\n",
       "Name: OriginalTweet, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove mentions and hashtags\n",
    "def remove_mentions_hashs(tweet):\n",
    "    tweet = re.sub(\"@[A-Za-z0-9_]+\",\"\", tweet) #Remove mentions\n",
    "    tweet = re.sub(\"#[A-Za-z0-9_]+\",\"\", tweet) #Remove hashtags\n",
    "    return tweet\n",
    "\n",
    "train_data['OriginalTweet'] = train_data['OriginalTweet'].apply(remove_mentions_hashs)\n",
    "train_data['OriginalTweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0431dcf3",
   "metadata": {
    "id": "0431dcf3",
    "outputId": "d0116e08-4f4b-4278-b9d8-9adae0629dfa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice talk neighbours family exchange phone n...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coronavirus australia: woolworths give elderly...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>news regionâs first confirmed covid-19 case c...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cashier grocery store sharing insights  prove ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet Sentiment\n",
       "0                                                      Neutral\n",
       "1  advice talk neighbours family exchange phone n...  Positive\n",
       "2  coronavirus australia: woolworths give elderly...  Positive\n",
       "5  news regionâs first confirmed covid-19 case c...  Positive\n",
       "6  cashier grocery store sharing insights  prove ...  Positive"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing emojis from tweets\n",
    "# https://stackoverflow.com/a/49146722/330558\n",
    "import re\n",
    "def remove_emojis(tweet):\n",
    "    pat =      re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return pat.sub(r'', tweet)\n",
    "\n",
    "train_data['OriginalTweet'] =train_data['OriginalTweet'].apply(remove_emojis)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21bdafee",
   "metadata": {
    "id": "21bdafee",
    "outputId": "d1338527-3afe-4728-85b9-b1f05b1ee4ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are some emojis ✂-➰\n",
      "These are some emojis -\n"
     ]
    }
   ],
   "source": [
    "#A simple demo of removing emojis\n",
    "text = u'These are some emojis \\U00002702-\\U000027B0'\n",
    "print(text) \n",
    "print(remove_emojis(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90050359",
   "metadata": {
    "id": "90050359",
    "outputId": "cc9a6b90-750e-48df-a60f-8b52ab3c70fe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice talk neighbours family exchange phone n...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coronavirus australia: woolworths give elderly...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>news regionas first confirmed covid-19 case ca...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cashier grocery store sharing insights  prove ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet Sentiment\n",
       "0                                                      Neutral\n",
       "1  advice talk neighbours family exchange phone n...  Positive\n",
       "2  coronavirus australia: woolworths give elderly...  Positive\n",
       "5  news regionas first confirmed covid-19 case ca...  Positive\n",
       "6  cashier grocery store sharing insights  prove ...  Positive"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://docs.python.org/2/library/unicodedata.html#unicodedata.normalize\n",
    "import unicodedata\n",
    "def remove_nonascii(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')# apply compatibility decomposition\n",
    "    return text\n",
    "train_data['OriginalTweet'] = train_data['OriginalTweet'].apply(remove_nonascii)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dacd5cf",
   "metadata": {},
   "source": [
    "#### After removing hashtags and mentions, it may happens that some tweets are left as blank strings, we will replace them with NaN below and then remove them from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "874d669f",
   "metadata": {
    "id": "874d669f"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_empty_strings1(tweet):\n",
    "    tweet = re.sub(r\"^\\s+|\\s+$\", 'NaN', tweet)\n",
    "    return tweet\n",
    "train_data['OriginalTweet'] =train_data['OriginalTweet'].apply(remove_empty_strings1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a92e8d4f",
   "metadata": {
    "id": "a92e8d4f"
   },
   "outputs": [],
   "source": [
    "## Removing all rows containing NaNs after removing hashtags, URLs\n",
    "train_data = train_data[train_data['OriginalTweet'] != 'NaN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8e504f5",
   "metadata": {
    "id": "f8e504f5",
    "outputId": "9a48ab26-892d-42d7-e9bf-ac110fec2c18"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice talk neighbours family exchange phone n...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coronavirus australia: woolworths give elderly...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>news regionas first confirmed covid-19 case ca...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cashier grocery store sharing insights  prove ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>supermarket today. buy toilet paper.NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet Sentiment\n",
       "1  advice talk neighbours family exchange phone n...  Positive\n",
       "2  coronavirus australia: woolworths give elderly...  Positive\n",
       "5  news regionas first confirmed covid-19 case ca...  Positive\n",
       "6  cashier grocery store sharing insights  prove ...  Positive\n",
       "7            supermarket today. buy toilet paper.NaN   Neutral"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc6615c7",
   "metadata": {
    "id": "bc6615c7",
    "outputId": "7b8f7b3d-6aef-4c74-86ee-00e05fa830ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>advice talk neighbours family exchange phone n...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coronavirus australia: woolworths give elderly...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news regionas first confirmed covid-19 case ca...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cashier grocery store sharing insights  prove ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>supermarket today. buy toilet paper.NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet Sentiment\n",
       "0  advice talk neighbours family exchange phone n...  Positive\n",
       "1  coronavirus australia: woolworths give elderly...  Positive\n",
       "2  news regionas first confirmed covid-19 case ca...  Positive\n",
       "3  cashier grocery store sharing insights  prove ...  Positive\n",
       "4            supermarket today. buy toilet paper.NaN   Neutral"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Resetting index of dataframe to start from 0\n",
    "train_data = train_data.reset_index(drop = True)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f347af",
   "metadata": {},
   "source": [
    "#### Spelling correction using TextBlob library's correct() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8fd74d5",
   "metadata": {
    "id": "f8fd74d5"
   },
   "outputs": [],
   "source": [
    "# TextBlob Spell correct() function takes looooong time to correct 41K rows, so we extract just 5 rows from our dataframe and \n",
    "# demonstrate spell correction using TextBlob correct() function\n",
    "smaller_train_data = train_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7d79a84",
   "metadata": {
    "id": "b7d79a84",
    "outputId": "5fb39c12-ce6f-4c2d-a154-204807d20dd6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaller_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd218264",
   "metadata": {
    "id": "fd218264",
    "outputId": "df0aa86c-0f30-4383-b2c1-48588b25e529"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SpellCorrectedTweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>advice talk neighbours family exchange phone n...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>advice talk neighbours family exchange phone n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coronavirus australia: woolworths give elderly...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>coronavirus australia: woolworths give elderly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news regionas first confirmed covid-19 case ca...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>news regions first confirmed could-19 case cam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cashier grocery store sharing insights  prove ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>cashier grocer store sharing insight  prove cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>supermarket today. buy toilet paper.NaN</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>supermarket today. buy toilet paper.a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet Sentiment  \\\n",
       "0  advice talk neighbours family exchange phone n...  Positive   \n",
       "1  coronavirus australia: woolworths give elderly...  Positive   \n",
       "2  news regionas first confirmed covid-19 case ca...  Positive   \n",
       "3  cashier grocery store sharing insights  prove ...  Positive   \n",
       "4            supermarket today. buy toilet paper.NaN   Neutral   \n",
       "\n",
       "                                 SpellCorrectedTweet  \n",
       "0  advice talk neighbours family exchange phone n...  \n",
       "1  coronavirus australia: woolworths give elderly...  \n",
       "2  news regions first confirmed could-19 case cam...  \n",
       "3  cashier grocer store sharing insight  prove cr...  \n",
       "4              supermarket today. buy toilet paper.a  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spelling correction\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from textblob import TextBlob   \n",
    "smaller_train_data['SpellCorrectedTweet'] = smaller_train_data['OriginalTweet'].apply(lambda x : str(TextBlob(x).correct()))\n",
    "smaller_train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b05c7b5",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac11b875",
   "metadata": {
    "id": "ac11b875",
    "outputId": "09055476-e519-43dd-b259-0fcb1554a070"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [advice, talk, neighbours, family, exchange, p...\n",
       "1    [coronavirus, australia:, woolworths, give, el...\n",
       "2    [news, regionas, first, confirmed, covid-19, c...\n",
       "3    [cashier, grocery, store, sharing, insights, p...\n",
       "4        [supermarket, today., buy, toilet, paper.NaN]\n",
       "Name: OriginalTweet, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will perform tokenization\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "def tokenize(text):\n",
    "    return tokenizer.tokenize(text)\n",
    "\n",
    "train_data['OriginalTweet'] = train_data['OriginalTweet'].apply(tokenize)\n",
    "train_data['OriginalTweet'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d69bcb",
   "metadata": {},
   "source": [
    "##### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7356a2f",
   "metadata": {
    "id": "e7356a2f",
    "outputId": "ce6fe6ff-c04a-41c9-b7c7-6932a0630399"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.28 s\n",
      "Wall time: 2.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[advice, talk, neighbour, family, exchange, ph...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[coronavirus, australia:, woolworth, give, eld...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[news, regionas, first, confirmed, covid-19, c...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[cashier, grocery, store, sharing, insight, pr...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[supermarket, today., buy, toilet, paper.NaN]</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet Sentiment\n",
       "0  [advice, talk, neighbour, family, exchange, ph...  Positive\n",
       "1  [coronavirus, australia:, woolworth, give, eld...  Positive\n",
       "2  [news, regionas, first, confirmed, covid-19, c...  Positive\n",
       "3  [cashier, grocery, store, sharing, insight, pr...  Positive\n",
       "4      [supermarket, today., buy, toilet, paper.NaN]   Neutral"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Here we perform lemmatization\n",
    "import nltk\n",
    "tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in text]\n",
    "\n",
    "train_data['OriginalTweet'] = train_data['OriginalTweet'].apply(lemmatize)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dc27ae",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5330629b",
   "metadata": {
    "id": "5330629b",
    "outputId": "74d5df0a-7041-474b-8d1d-b910ba8e79a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[advic, talk, neighbour, famili, exchang, phon...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[coronaviru, australia:, woolworth, give, elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[news, regiona, first, confirm, covid-19, case...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[cashier, groceri, store, share, insight, prov...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[supermarket, today., buy, toilet, paper.nan]</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet Sentiment\n",
       "0  [advic, talk, neighbour, famili, exchang, phon...  Positive\n",
       "1  [coronaviru, australia:, woolworth, give, elde...  Positive\n",
       "2  [news, regiona, first, confirm, covid-19, case...  Positive\n",
       "3  [cashier, groceri, store, share, insight, prov...  Positive\n",
       "4      [supermarket, today., buy, toilet, paper.nan]   Neutral"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stemming(text):\n",
    "    return [stemmer.stem(w) for w in text]\n",
    "\n",
    "train_data['OriginalTweet'] = train_data['OriginalTweet'].apply(stemming)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8b7d764",
   "metadata": {
    "id": "d8b7d764",
    "outputId": "1e7e7d10-51f7-484c-b88f-6ccee52387d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[advic, talk, neighbour, famili, exchang, phon...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[coronaviru, australia:, woolworth, give, elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[news, regiona, first, confirm, covid-19, case...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[cashier, groceri, store, share, insight, prov...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[supermarket, today., buy, toilet, paper.nan]</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet Sentiment\n",
       "0  [advic, talk, neighbour, famili, exchang, phon...  Positive\n",
       "1  [coronaviru, australia:, woolworth, give, elde...  Positive\n",
       "2  [news, regiona, first, confirm, covid-19, case...  Positive\n",
       "3  [cashier, groceri, store, share, insight, prov...  Positive\n",
       "4      [supermarket, today., buy, toilet, paper.nan]   Neutral"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d06b28a",
   "metadata": {
    "id": "0d06b28a"
   },
   "source": [
    "#### Now we will do some data visualization, first we will plot the most frequent words in data using matplotlib then we will use scattertext  to display words in positive and negative sentiment categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1529a63e",
   "metadata": {
    "id": "1529a63e",
    "outputId": "56adfc03-a814-435b-fe76-860e1d677adb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Neutral', 'Negative', 'Extremely Positive',\n",
       "       'Extremely Negative'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227d59e3",
   "metadata": {},
   "source": [
    "#### Counting most frequent words in tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46ca04cd",
   "metadata": {
    "id": "46ca04cd"
   },
   "outputs": [],
   "source": [
    "# Counting most frequent words in tweets\n",
    "#https://docs.python.org/3/library/itertools.html#itertools.chain\n",
    "import itertools\n",
    "import collections\n",
    "all_tweets = list(train_data[\"OriginalTweet\"])\n",
    "all_tokens = list(itertools.chain(*all_tweets))\n",
    "token_counts = collections.Counter(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ea0d447",
   "metadata": {
    "id": "7ea0d447",
    "outputId": "ccd45391-9065-446a-bee6-21a50c3ef68e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('price', 5786),\n",
       " ('store', 5088),\n",
       " ('groceri', 4886),\n",
       " ('food', 4716),\n",
       " ('supermarket', 4670),\n",
       " ('covid-19', 4281),\n",
       " ('consum', 3884),\n",
       " ('peopl', 3788),\n",
       " ('shop', 3203),\n",
       " ('go', 3197)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c488fc6",
   "metadata": {
    "id": "1c488fc6",
    "outputId": "9efd1bc3-2517-46ce-e3b2-2845714597ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>price</td>\n",
       "      <td>5786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>store</td>\n",
       "      <td>5088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>groceri</td>\n",
       "      <td>4886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>food</td>\n",
       "      <td>4716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>supermarket</td>\n",
       "      <td>4670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Token  Count\n",
       "0        price   5786\n",
       "1        store   5088\n",
       "2      groceri   4886\n",
       "3         food   4716\n",
       "4  supermarket   4670"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(token_counts.most_common(20), columns=['Token','Count'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0f2d7f3",
   "metadata": {
    "id": "c0f2d7f3",
    "outputId": "a07ac5e3-d553-4a6e-efb7-2e09f1fb60f2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (12,8)\n",
    "df.sort_values(by = 'Count').plot.bar(x='Token', y='Count')\n",
    "plt.title('Most Used Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d505ba",
   "metadata": {
    "id": "d1d505ba"
   },
   "source": [
    "### scattertext library\n",
    "\n",
    "https://github.com/JasonKessler/scattertext/blob/master/README.md\n",
    "\n",
    "- scattertext is a tool for finding distinguishing terms in corpora and displaying them in an interactive HTML scatter plot. \n",
    "- Points corresponding to terms are selectively labeled so that they don't overlap with other labels or points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8775f9a",
   "metadata": {
    "id": "b8775f9a"
   },
   "outputs": [],
   "source": [
    "# installing scattertext from JupyterNotebook, to install uncomment the below line of code\n",
    "#!pip install scattertext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d5a8f0e",
   "metadata": {
    "id": "3d5a8f0e",
    "outputId": "c166e7a8-195d-441a-887a-a5ae2e214b47"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[advic, talk, neighbour, famili, exchang, phon...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[coronaviru, australia:, woolworth, give, elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[news, regiona, first, confirm, covid-19, case...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[cashier, groceri, store, share, insight, prov...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[supermarket, today., buy, toilet, paper.nan]</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet Sentiment\n",
       "0  [advic, talk, neighbour, famili, exchang, phon...  Positive\n",
       "1  [coronaviru, australia:, woolworth, give, elde...  Positive\n",
       "2  [news, regiona, first, confirm, covid-19, case...  Positive\n",
       "3  [cashier, groceri, store, share, insight, prov...  Positive\n",
       "4      [supermarket, today., buy, toilet, paper.nan]   Neutral"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c154f08",
   "metadata": {
    "id": "8c154f08",
    "outputId": "5d701288-c681-49eb-bfd5-4b1758437b99"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[advic, talk, neighbour, famili, exchang, phon...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[coronaviru, australia:, woolworth, give, elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[news, regiona, first, confirm, covid-19, case...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[cashier, groceri, store, share, insight, prov...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[due, covid-19, retail, store, classroom, atla...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet Sentiment\n",
       "0  [advic, talk, neighbour, famili, exchang, phon...  Positive\n",
       "1  [coronaviru, australia:, woolworth, give, elde...  Positive\n",
       "2  [news, regiona, first, confirm, covid-19, case...  Positive\n",
       "3  [cashier, groceri, store, share, insight, prov...  Positive\n",
       "5  [due, covid-19, retail, store, classroom, atla...  Positive"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_neg_tweets = train_data.loc[(train_data['Sentiment']=='Negative')|(train_data['Sentiment']=='Positive')]\n",
    "pos_neg_tweets.reset_index(drop = True)\n",
    "pos_neg_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3e73258",
   "metadata": {
    "id": "f3e73258",
    "outputId": "364149f0-4b23-4f8a-9450-bdadbbc4a7bc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>advic, talk, neighbour, famili, exchang, phone...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coronaviru, australia:, woolworth, give, elder...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news, regiona, first, confirm, covid-19, case,...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cashier, groceri, store, share, insight, prove...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>due, covid-19, retail, store, classroom, atlan...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet Sentiment\n",
       "0  advic, talk, neighbour, famili, exchang, phone...  Positive\n",
       "1  coronaviru, australia:, woolworth, give, elder...  Positive\n",
       "2  news, regiona, first, confirm, covid-19, case,...  Positive\n",
       "3  cashier, groceri, store, share, insight, prove...  Positive\n",
       "5  due, covid-19, retail, store, classroom, atlan...  Positive"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# converting token lists to strings using join() on each row or the OriginalTweet column\n",
    "pos_neg_tweets['OriginalTweet'] = pos_neg_tweets.loc[:, 'OriginalTweet'].apply(lambda x: ', '.join(x))\n",
    "pos_neg_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf2549d",
   "metadata": {},
   "source": [
    "#### Parsing OriginalTweet column using SpaCy's NLP pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d47398c1",
   "metadata": {
    "id": "d47398c1",
    "outputId": "44c54998-4ec5-48fd-9b52-b16a5daee2ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>advic, talk, neighbour, famili, exchang, phone...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>(advic, ,, talk, ,, neighbour, ,, famili, ,, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coronaviru, australia:, woolworth, give, elder...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>(coronaviru, ,, australia, :, ,, woolworth, ,,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news, regiona, first, confirm, covid-19, case,...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>(news, ,, regiona, ,, first, ,, confirm, ,, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cashier, groceri, store, share, insight, prove...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>(cashier, ,, groceri, ,, store, ,, share, ,, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>due, covid-19, retail, store, classroom, atlan...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>(due, ,, covid-19, ,, retail, ,, store, ,, cla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet Sentiment  \\\n",
       "0  advic, talk, neighbour, famili, exchang, phone...  Positive   \n",
       "1  coronaviru, australia:, woolworth, give, elder...  Positive   \n",
       "2  news, regiona, first, confirm, covid-19, case,...  Positive   \n",
       "3  cashier, groceri, store, share, insight, prove...  Positive   \n",
       "5  due, covid-19, retail, store, classroom, atlan...  Positive   \n",
       "\n",
       "                                              parsed  \n",
       "0  (advic, ,, talk, ,, neighbour, ,, famili, ,, e...  \n",
       "1  (coronaviru, ,, australia, :, ,, woolworth, ,,...  \n",
       "2  (news, ,, regiona, ,, first, ,, confirm, ,, co...  \n",
       "3  (cashier, ,, groceri, ,, store, ,, share, ,, i...  \n",
       "5  (due, ,, covid-19, ,, retail, ,, store, ,, cla...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "def parsetweets(text):\n",
    "    text = text\n",
    "    parsedtext = nlp(text)\n",
    "    return parsedtext\n",
    "\n",
    "\n",
    "pos_neg_tweets['parsed'] = pos_neg_tweets.loc[:,'OriginalTweet'].apply(parsetweets)\n",
    "pos_neg_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438a0259",
   "metadata": {},
   "source": [
    "#### Plotting an interactive scattertext display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44a4368b",
   "metadata": {
    "id": "44a4368b",
    "outputId": "45fd5c6e-478e-4d3f-cc2b-ebe131a5dac1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"700\"\n",
       "            src=\"posnegtweets.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1b02f9d4850>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scattertext as st\n",
    "from IPython.display import IFrame, display, HTML\n",
    "from scattertext import CorpusFromPandas, produce_scattertext_explorer\n",
    "\n",
    "corpus = st.CorpusFromParsedDocuments(pos_neg_tweets.iloc[:1000,:], category_col ='Sentiment', parsed_col='parsed').build()\n",
    "html = st.produce_scattertext_explorer(corpus, category = 'Negative', category_name='Negative',\n",
    "                                      not_category_name='Positive', minimum_term_frequency=10,\n",
    "                                      width_in_pixels=1000, transform = st.Scalers.log_scale_standardize)\n",
    "file_name = 'posnegtweets.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 800, height = 700)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6e114f",
   "metadata": {
    "id": "6f6e114f"
   },
   "source": [
    "## References Text Representation\n",
    "1. https://nlp-ensae.github.io/files/2-ML-FOR-NLP-2022.pdf\n",
    "2. https://www.scaler.com/topics/nlp/text-representation-in-nlp/\n",
    "3. https://nlp-ensae.github.io/materials/course2/\n",
    "4. https://nlp-ensae.github.io/files/2-ML-FOR-NLP-2022.pdf\n",
    "5. https://nlp-ensae.github.io/materials/\n",
    "6. https://www.analyticsvidhya.com/blog/2022/02/machine-learning-techniques-for-text-representation-in-nlp/\n",
    "7. https://towardsdatascience.com/introduction-to-text-representations-for-language-processing-part-1-dc6e8068b8a4\n",
    "8. https://appliedsingularity.com/2022/01/04/nlp-tutorials%E2%80%8A-%E2%80%8Apart-2-text-representation-word-embeddings/#:~:text=To%20put%20it%20in%20simple,pipeline%20after%20Text%20Pre%2Dprocessing.\n",
    "9. https://medium.com/analytics-vidhya/deep-learning-techniques-for-text-representation-part-1-75c4ad4aa133\n",
    "10. https://www.youtube.com/watch?v=viZrOnJclY0\n",
    "11. https://appliedsingularity.com/2022/01/04/nlp-tutorials%E2%80%8A-%E2%80%8Apart-2-text-representation-word-embeddings/#:~:text=To%20put%20it%20in%20simple,pipeline%20after%20Text%20Pre%2Dprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a615cb85",
   "metadata": {
    "id": "a615cb85"
   },
   "source": [
    "### Text Representation\n",
    "\n",
    "- Text data exists in the form of alphabets, words, symbols, digits, or a collection of all of these. E.g. 'India', ',', 'Covid19' etc. \n",
    "- Before we can apply machine learning/deep learning algorithms to text data, we must represent the text in numerical form. Both the individual words and well as documents of text can be converted into vectors of floating point-numbers. \n",
    "- The process of representing a token, a sentence as a numerical vector is called 'Embedding', the multi-dimensional space of these vectors is called as the embedding space. \n",
    "- Deep neural network archictures like Recurrent Neural Networks, Long Short Term Memory networks, Transformers require text to be input in the form of fixed-dimensional numerical vectors. \n",
    "\n",
    "#### Some terminology:\n",
    "1. Document: A document is a collection of many words. \n",
    "2. Vocabulary: Vocabulary is the set of unique words in a document.\n",
    "3. Token: A token is a basic unit of discrete data. It often refers to a single word or a punctuation mark.\n",
    "4. Corpus: A corpus is a collection of documents.\n",
    "5. Context : Context of a word/token is the words/tokens that surround it on left and right in the document.\n",
    "6. Vector Embedding: Vector based numerical representations of text are called as Embedding. E.g., word2vec or GLoVE are unsupervised methods based on corpus statistics. Frameworks like tensorflow and keras support “Embedding layers”. \n",
    "\n",
    "#### Text representation should have following properties:\n",
    "1. It should uniquely identify a word (has to be a bijection)\n",
    "2. Should capture the morphological, syntactic and semantic similarity among words. Related words should appear closer in Eudlidean space than the unrelated words. \n",
    "3. Arithmetic operations should be possible on these representations. \n",
    "4. Tasks like computing word similarities and relationships should be easy with the representations. \n",
    "5. It should be easy to map from word to its embedding easily and vice versa. \n",
    "\n",
    "#### Some prominent techniques for text representation: \n",
    "\n",
    "1. One-Hot Encoding\n",
    "2. Bag of Words Model - CountVectorizer and CountVectorizer with n-grams\n",
    "3. Tf-Idf Model\n",
    "5. Word2Vec Embedding\n",
    "6. GloVe Embedding\n",
    "7. FastText Embedding\n",
    "8. Transformers like ChatGPT and BERT use their own dynamical embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87565627",
   "metadata": {
    "id": "87565627"
   },
   "source": [
    "##### One-Hot Encoding : \n",
    "This is the simplest technique of representing text as numerical vectors. Every word is represented as a unique 'One-Hot' binary vector of 0s and 1s. For every unique word in the vocabulary, the vector contains a single 1 and rest all values are 0s, the position of 1 in the vector uniquely identifies a word. \n",
    "\n",
    "Example:\n",
    "\n",
    "|Fruit|\tApple|\tBanana|\tOrange|\tMango|\tVector|\n",
    "|-    |-  |-     |-     |-     |-       |\n",
    "|Apple|\t1    |\t0|\t0\t|0\t|[1, 0, 0, 0]|\n",
    "|Banana|\t0|\t1|\t0\t|0\t|[0, 1, 0, 0]|\n",
    "|Orange|\t0|\t0|\t1\t|0\t|[0, 0, 1, 0]|\n",
    "|Mango|\t0|\t0|\t0\t|1\t|[0, 0, 0, 1]|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dce25a87",
   "metadata": {
    "id": "dce25a87",
    "outputId": "9ae0e9dd-237e-4acd-b363-b765da7976af"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "document = \"The rose is red. The violet is blue.\"\n",
    "document = document.split()\n",
    "tokens = [doc.split(\" \") for doc in document]\n",
    "\n",
    "wordids = {token: idx for idx, token in enumerate(set(document))}\n",
    "tokenids = [[wordids[token] for token in toke] for toke in tokens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e1a3f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'rose', 'is', 'red.', 'The', 'violet', 'is', 'blue.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ccd99cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The'], ['rose'], ['is'], ['red.'], ['The'], ['violet'], ['is'], ['blue.']]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4de55061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is': 0, 'rose': 1, 'The': 2, 'blue.': 3, 'red.': 4, 'violet': 5}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bdd5a0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2], [1], [0], [4], [2], [5], [0], [3]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "462095c2",
   "metadata": {
    "id": "462095c2",
    "outputId": "e3d3790f-f590-4f17-dcf6-d7847c479922"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "onehotmodel = OneHotEncoder()\n",
    "vectors = onehotmodel.fit_transform(tokenids)\n",
    "print(vectors.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66181768",
   "metadata": {
    "id": "66181768"
   },
   "source": [
    "#### Bag of words representation: CountVectorizer\n",
    "https://en.wikipedia.org/wiki/Bag-of-words_model\n",
    "\n",
    "Bag-of-words(BoW) is an orderless representation of text that describes the occurrence of words within a document. It has a vocabulary of known words in the document and a measure of the presence of known words. Bag-of-words model does not contain any information about the order or structure of words in the document. \n",
    "\n",
    "Example:\n",
    "\n",
    "Document1: John likes to watch movies. Mary likes movies too.\n",
    "\n",
    "Document2: Mary also likes to watch football games.\n",
    "\n",
    "Vocabulary1: \"John\",\"likes\",\"to\",\"watch\",\"movies\",\"Mary\",\"likes\",\"movies\",\"too\"\n",
    "\n",
    "Vocabulary2: \"Mary\",\"also\",\"likes\",\"to\",\"watch\",\"football\",\"games\"\n",
    "\n",
    "BoW1 = {\"John\":1,\"likes\":2,\"to\":1,\"watch\":1,\"movies\":2,\"Mary\":1,\"too\":1};\n",
    "\n",
    "BoW2 = {\"Mary\":1,\"also\":1,\"likes\":1,\"to\":1,\"watch\":1,\"football\":1,\"games\":1};\n",
    "\n",
    "\n",
    "Document3 is a union of document1 and document2 (has the words from document 1 and document 2)\n",
    "\n",
    "Document3: John likes to watch movies. Mary likes movies too. Mary also likes to watch football games.\n",
    "\n",
    "BoW3: {\"John\":1,\"likes\":3,\"to\":2,\"watch\":2,\"movies\":2,\"Mary\":2,\"too\":1,\"also\":1,\"football\":1,\"games\":1};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f17be033",
   "metadata": {
    "id": "f17be033"
   },
   "outputs": [],
   "source": [
    "# This process_text() function returns list of cleaned tokens of the text\n",
    "import numpy\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def process_text(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.lower()\n",
    "    text = \" \".join([word for word in str(text).split() if word not in stop_words])\n",
    "    text = \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "23eef16c",
   "metadata": {
    "id": "23eef16c",
    "outputId": "69fb5051-b197-4a9b-af59-41058d78c30c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rose', 'red', 'violet', 'blue']\n",
      "  (0, 2)\t1\n",
      "  (1, 1)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 0)\t1\n"
     ]
    }
   ],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "#https://stackoverflow.com/questions/27697766/understanding-min-df-and-max-df-in-scikit-countvectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import nltk\n",
    "document = [\"The\", \"rose\", \"is\", \"red\", \"The\",  \"violet\", \"is\", \"blue\"] #, \"This is some text, just for demonstration\"]\n",
    "\n",
    "processed_document = [process_text(item) for item in document]\n",
    "processed_document = [x for x in processed_document if x != '']\n",
    "print(processed_document)\n",
    "\n",
    "bow_countvect = CountVectorizer(min_df = 0., max_df = 1.)\n",
    "\n",
    "matrix = bow_countvect.fit_transform(processed_document)\n",
    "matrix.toarray()\n",
    "vocabulary = bow_countvect.get_feature_names_out()\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a3fa24",
   "metadata": {
    "id": "c4a3fa24"
   },
   "source": [
    "#### Compressed Sparse Row format\n",
    "\n",
    "<img src = 'compressedsparserowformat.png'>\n",
    "<center>Source: https://phys.libretexts.org/Bookshelves/Mathematical_Physics_and_Pedagogy/Computational_Physics_(Chong)/08%3A_Sparse_Matrices/8.02%3A_Sparse_Matrix_Formats</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50376256",
   "metadata": {
    "id": "50376256",
    "outputId": "5470b131-4c1f-41da-b78a-fb808538525b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['blue', 'red', 'rose', 'violet'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3bfbdff",
   "metadata": {
    "id": "e3bfbdff",
    "outputId": "2bb04854-1c8f-4050-83dd-31838acf763c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 1, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3530414c",
   "metadata": {
    "id": "3530414c"
   },
   "source": [
    "#### Bag of words representation: n-grams\n",
    "Simpe Bag-of-words model does not store the information about the order of words.  The n-gram model can store this spatial information. \n",
    "\n",
    "A word/token is known as a 'gram'. An n-gram is a contiguous group of n-tokens that appear in a text document.  \n",
    "A unigram means 1 word, bigrams means two words, a trigram refers to a group of 3 words...\n",
    "\n",
    "For example for the text:\n",
    "\n",
    "<b>Document1: John likes to watch movies. Mary likes movies too.</b>\n",
    "\n",
    "A bigram model will parse the text into the following units and store the term frequency of each unit as in simple BoW model. \n",
    "\n",
    "<b>[\"John likes\", \"likes to\", \"to watch\", \"watch movies\", \"Mary likes\", \"likes movies\", \"movies too\",]</b>\n",
    "\n",
    "Bag-of-word model can be thought of as a special case of the n-gram model, with n=1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81b2efc4",
   "metadata": {
    "id": "81b2efc4",
    "outputId": "7fa5494c-d01e-4724-ce43-467dcda5b0b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x4 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "document = [\"The rose is red.\", \"The violet is blue.\", \"This is some text, just for demonstration\"]\n",
    "ngram_countvect = CountVectorizer(ngram_range = (2, 2), stop_words = 'english')\n",
    "#ngram_range paramenter to count vectorizer indicates the lower and upper boundary of the range of n-values for \n",
    "#different word n-grams or char n-grams to be extracted. All values of n such such that min_n <= n <= max_n will be used. \n",
    "#For example an ngram_range of (1, 1) means only unigrams, (1, 2) means unigrams and bigrams, and (2, 2) means only bigrams.\n",
    "\n",
    "matrix = ngram_countvect.fit_transform(document)\n",
    "vocabulary = ngram_countvect.get_feature_names_out()\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d55465a9",
   "metadata": {
    "id": "d55465a9",
    "outputId": "fb283a8e-ae7b-421d-e230-91084d35149f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['just demonstration', 'rose red', 'text just', 'violet blue'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "56d3f038",
   "metadata": {
    "id": "56d3f038",
    "outputId": "7c982169-ad0f-4326-d17f-d44ff7154423"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 1, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [1, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52b5f36",
   "metadata": {
    "id": "e52b5f36"
   },
   "source": [
    "### Tf-Idf Vectorizer : Term Frequency - Inverse Document Frequency \n",
    "https://monkeylearn.com/blog/what-is-tf-idf/\n",
    "\n",
    "- The Tf-Idf score, tfidf(w,D) of a term/word 'w' in a document 'd', is a product of two metrics - term frequency (tf) and inverse document frequency (idf). i.e.,\n",
    "\n",
    "$$ tfidf(w, d, C) = tf(w,d)*idf(w,d,C) $$\n",
    "\n",
    "- Where w is the term or word, d is the document, C is corpus containing a total of N documents including document d. \n",
    "\n",
    "- Term frequency, tf(w,d), is the frequency of word w in document d. Term frequency may be adjusted for the length of the document (raw count of occurences divided by number of words in the document), it may be Logarithmically scaled frequency (e.g. log(1 + raw count)), or it may be Boolean frequency (e.g. 1 if the term occurs, or 0 if the term does not occur, in the document).\n",
    "\n",
    "- The inverse document frequency of a word is calculated across a set of documents (a corpus).Document Frequency: Is the frequency of occurence of a term/word w in a set of N documents (a corpus).\n",
    "\n",
    "\n",
    "- Inverse Document Frequency is a measure of how common or rare a word is in the corpus. Less is the IDF, more common is the word and vice versa. IDF of a word is calculated by taking the log of the total number of documents in corpus divided by the number of documents that contain a word. \n",
    "\n",
    "\n",
    "- Inverse Document Frequency of a term/word w, in a total of N documents in corpus (C) is defined as :\n",
    "\n",
    "$$  ifd(w, d, C) = log\\frac{N}{(count(d \\in C, w \\in d))} = log\\frac{total no. of documents in C}{number of documents containing word w}$$\n",
    "\n",
    "\n",
    "\n",
    "The denominator is simply the number of documents in which the word, w, appears in. \n",
    "Inverse document frequency is a measure of informativeness of a term/word. Frequently occuring words are less informative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5dcdd65",
   "metadata": {
    "id": "f5dcdd65",
    "outputId": "0e9dc713-3a2c-4812-f7fb-9f5d8f6d9ced"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.34520502, 0.        ,\n",
       "        0.5844829 , 0.5844829 , 0.        , 0.        , 0.44451431,\n",
       "        0.        , 0.        ],\n",
       "       [0.5844829 , 0.        , 0.        , 0.34520502, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.44451431,\n",
       "        0.        , 0.5844829 ],\n",
       "       [0.        , 0.39687454, 0.39687454, 0.2344005 , 0.39687454,\n",
       "        0.        , 0.        , 0.39687454, 0.39687454, 0.        ,\n",
       "        0.39687454, 0.        ]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "document = [\"The rose is red.\", \"The violet is blue.\", \"This is some text, just for demonstration\"]\n",
    "\n",
    "tf_idf = TfidfVectorizer(min_df = 0., max_df = 1., use_idf = True)\n",
    "tf_idf_matrix = tf_idf.fit_transform(document)\n",
    "tf_idf_matrix = tf_idf_matrix.toarray()\n",
    "tf_idf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746050cb",
   "metadata": {
    "id": "746050cb"
   },
   "source": [
    "#### Word Embeddings\n",
    "\n",
    "Above methods of text representation often do not capture the semantics and context of the words. \n",
    "To overcome these limitations we use Embeddings. The embeddings are learnt by training a model of huge datasets. These embeddings capture the context of a word by taking account of neighbourning words in the sentence and the order of the words in the sentence. Three prominent Word Embeddings are:\n",
    "\n",
    "1. Word2Vec\n",
    "2. GloVe\n",
    "3. FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sCls7-ByBf1N",
   "metadata": {
    "id": "sCls7-ByBf1N"
   },
   "source": [
    "### Word2Vec\n",
    "- Is an unsupervised model trained on huge text corpora. It creates a vocabulary of words and  a distributed and continuous \n",
    "dense vector representations of words in the vector space representing the vocabulary. It captures contextual and semantic similarity. \n",
    "\n",
    "- We can specify the size of the word embedding vectors. The total number of vectors are essentially the size of the vocabulary. \n",
    "- There are two different model architecture types in Word2Vec - CBOW (Continuous Bag of Words) Model, Skip Gram Model\n",
    "\n",
    "CBOW Model - This architecture tries to predict the current target word based on the source context words.\n",
    "For example, in the sentence “The rose is red and beautiful.” The context word may be 'rose' and the target word may be 'red'. We can change the window size of context words to include more words in context. \n",
    "\n",
    "Skip Gram Model: This architecture tries to predict the source context words given a target word.\n",
    "For example, in the CBOW model, given a target word 'red', it will try to predict the context word 'rose'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9559c665",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9559c665",
    "outputId": "167e2183-f33f-4fee-9e62-c93ec94e9148"
   },
   "outputs": [],
   "source": [
    "#https://radimrehurek.com/gensim/models/word2vec.html\n",
    "from gensim.models import word2vec\n",
    "import nltk\n",
    "document = [\"The rose is red.\", \"The violet is blue.\", \"This is some text, just for demonstration\"]\n",
    "\n",
    "tokenized_corpus = [nltk.word_tokenize(doc) for doc in document]\n",
    "\n",
    "#parameters of word2vec model\n",
    "# feature_size : integer   :  Word vector dimensionality\n",
    "# window_context : integer :  The maximum distance between the current and predicted word within a sentence.(2, 10)\n",
    "# min_word_count : integer : Ignores all words with total absolute frequency lower than this - (2, 100)\n",
    "# sample : integer  : The threshold for configuring which higher-frequency words are randomly downsampled. Highly influencial. - (0, 1e-5)\n",
    "# sg: integer: Skip-gram model configuration, CBOW by default\n",
    "\n",
    "wordtovector = word2vec.Word2Vec(tokenized_corpus,  window = 3, min_count = 1, sg = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f63f8181",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f63f8181",
    "outputId": "dd8e9716-09b3-400d-be52-a34730009a42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding of the word blue\n",
      "[ 7.0882346e-03 -1.5676125e-03  7.9485057e-03 -9.4885454e-03\n",
      " -8.0291154e-03 -6.6414177e-03 -4.0035537e-03  4.9901577e-03\n",
      " -3.8140828e-03 -8.3210431e-03  8.4121935e-03 -3.7481326e-03\n",
      "  8.6085498e-03 -4.8952354e-03  3.9191782e-03  4.9230834e-03\n",
      "  2.3934911e-03 -2.8181269e-03  2.8488615e-03 -8.2567530e-03\n",
      " -2.7654334e-03 -2.5918004e-03  7.2503285e-03 -3.4646827e-03\n",
      " -6.5993182e-03  4.3409867e-03 -4.7505699e-04 -3.5972693e-03\n",
      "  6.8826573e-03  3.8732646e-03 -3.8993151e-03  7.7144802e-04\n",
      "  9.1439383e-03  7.7544516e-03  6.3626450e-03  4.6678651e-03\n",
      "  2.3853800e-03 -1.8410536e-03 -6.3705896e-03 -3.0080444e-04\n",
      " -1.5646036e-03 -5.7308871e-04 -6.2642270e-03  7.4344152e-03\n",
      " -6.5921983e-03 -7.2388030e-03 -2.7566419e-03 -1.5156541e-03\n",
      " -7.6359692e-03  6.9847569e-04 -5.3255404e-03 -1.2766641e-03\n",
      " -7.3655392e-03  1.9610589e-03  3.2732745e-03 -2.2214423e-05\n",
      " -5.4476624e-03 -1.7254592e-03  7.0852255e-03  3.7373139e-03\n",
      " -8.8824788e-03 -3.4133841e-03  2.3537194e-03  2.1375741e-03\n",
      " -9.4641317e-03  4.5720097e-03 -8.6566145e-03 -7.3881103e-03\n",
      "  3.4841239e-03 -3.4704185e-03  3.5642558e-03  8.8936128e-03\n",
      " -3.5739194e-03  9.3216542e-03  1.7110441e-03  9.8475739e-03\n",
      "  5.7045724e-03 -9.1502620e-03 -3.3273466e-03  6.5301284e-03\n",
      "  5.6020524e-03  8.7064151e-03  6.9270218e-03  8.0386195e-03\n",
      " -9.8234154e-03  4.2988323e-03 -5.0303498e-03  3.5114863e-03\n",
      "  6.0573174e-03  4.3918467e-03  7.5128917e-03  1.4976227e-03\n",
      " -1.2647685e-03  5.7678455e-03 -5.6401771e-03  3.8886574e-05\n",
      "  9.4576962e-03 -5.4818150e-03  3.8134370e-03 -8.1129698e-03]\n",
      "Size of Embedding of the word blue\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print('Embedding of the word blue')\n",
    "print(wordtovector.wv['blue'])\n",
    "\n",
    "print('Size of Embedding of the word blue')\n",
    "print(wordtovector.wv['blue'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab02dc4",
   "metadata": {},
   "source": [
    "#### All the vectors for all the words in our input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c6ad1049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.3638243e-04,  2.3663043e-04,  5.1046940e-03, ...,\n",
       "        -7.0424662e-03,  9.0095052e-04,  6.3923588e-03],\n",
       "       [-8.6196875e-03,  3.6657380e-03,  5.1898835e-03, ...,\n",
       "        -2.3915148e-03, -9.5100952e-03,  4.5058774e-03],\n",
       "       [ 9.4563962e-05,  3.0773187e-03, -6.8126465e-03, ...,\n",
       "         5.1259040e-04,  8.2130842e-03, -7.0190406e-03],\n",
       "       ...,\n",
       "       [ 9.7702928e-03,  8.1651136e-03,  1.2809705e-03, ...,\n",
       "        -2.9727411e-03, -4.9318983e-03, -2.3151112e-03],\n",
       "       [-1.9442177e-03, -5.2675223e-03,  9.4471117e-03, ...,\n",
       "         5.9827138e-03,  6.8153618e-03,  7.8225443e-03],\n",
       "       [-9.5001198e-03,  9.5622232e-03, -7.7707553e-03, ...,\n",
       "        -3.1351089e-03, -6.3388203e-03,  9.8700766e-03]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = wordtovector.wv.index_to_key\n",
    "wvs = wordtovector.wv[words]\n",
    "wvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d9943073",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "d9943073",
    "outputId": "d464b12e-722a-4d1d-e3af-f0cb986cbc71"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>-0.000536</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.005105</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>-0.009303</td>\n",
       "      <td>-0.007118</td>\n",
       "      <td>0.006459</td>\n",
       "      <td>0.008974</td>\n",
       "      <td>-0.005016</td>\n",
       "      <td>-0.003765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.003474</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.009618</td>\n",
       "      <td>0.005061</td>\n",
       "      <td>-0.008916</td>\n",
       "      <td>-0.007042</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.006392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>-0.008620</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.007467</td>\n",
       "      <td>-0.006168</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.006047</td>\n",
       "      <td>-0.002840</td>\n",
       "      <td>-0.006174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>-0.001576</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>-0.007882</td>\n",
       "      <td>-0.002717</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>0.005347</td>\n",
       "      <td>-0.002392</td>\n",
       "      <td>-0.009510</td>\n",
       "      <td>0.004506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The</th>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>-0.006813</td>\n",
       "      <td>-0.001375</td>\n",
       "      <td>0.007669</td>\n",
       "      <td>0.007346</td>\n",
       "      <td>-0.003673</td>\n",
       "      <td>0.002643</td>\n",
       "      <td>-0.008317</td>\n",
       "      <td>0.006205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004509</td>\n",
       "      <td>0.005702</td>\n",
       "      <td>0.009180</td>\n",
       "      <td>-0.004100</td>\n",
       "      <td>0.007965</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.005879</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.008213</td>\n",
       "      <td>-0.007019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demonstration</th>\n",
       "      <td>-0.008243</td>\n",
       "      <td>0.009299</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.001967</td>\n",
       "      <td>0.004604</td>\n",
       "      <td>-0.004095</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>0.006940</td>\n",
       "      <td>0.006065</td>\n",
       "      <td>-0.007511</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007426</td>\n",
       "      <td>-0.001064</td>\n",
       "      <td>-0.000795</td>\n",
       "      <td>-0.002563</td>\n",
       "      <td>0.009683</td>\n",
       "      <td>-0.000459</td>\n",
       "      <td>0.005874</td>\n",
       "      <td>-0.007448</td>\n",
       "      <td>-0.002506</td>\n",
       "      <td>-0.005550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>-0.007139</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>-0.007177</td>\n",
       "      <td>-0.002245</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>0.005833</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>-0.004110</td>\n",
       "      <td>0.007225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>-0.004713</td>\n",
       "      <td>0.005281</td>\n",
       "      <td>-0.004233</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>-0.008046</td>\n",
       "      <td>0.006210</td>\n",
       "      <td>0.004819</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.003013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>-0.008727</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>-0.000874</td>\n",
       "      <td>-0.009319</td>\n",
       "      <td>-0.009428</td>\n",
       "      <td>-0.001411</td>\n",
       "      <td>0.004432</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>-0.006499</td>\n",
       "      <td>-0.006873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009071</td>\n",
       "      <td>0.008938</td>\n",
       "      <td>-0.008208</td>\n",
       "      <td>-0.003012</td>\n",
       "      <td>0.009887</td>\n",
       "      <td>0.005104</td>\n",
       "      <td>-0.001588</td>\n",
       "      <td>-0.008692</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>-0.006676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.008132</td>\n",
       "      <td>-0.004457</td>\n",
       "      <td>-0.001068</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.006114</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.003246</td>\n",
       "      <td>-0.001511</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002701</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>-0.003537</td>\n",
       "      <td>-0.000419</td>\n",
       "      <td>-0.000709</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.008195</td>\n",
       "      <td>-0.005737</td>\n",
       "      <td>-0.001660</td>\n",
       "      <td>0.005572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>0.008168</td>\n",
       "      <td>-0.004443</td>\n",
       "      <td>0.008985</td>\n",
       "      <td>0.008254</td>\n",
       "      <td>-0.004435</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.004274</td>\n",
       "      <td>-0.003926</td>\n",
       "      <td>-0.005560</td>\n",
       "      <td>-0.006512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>-0.004004</td>\n",
       "      <td>-0.008241</td>\n",
       "      <td>0.006278</td>\n",
       "      <td>-0.001949</td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>-0.001771</td>\n",
       "      <td>-0.004536</td>\n",
       "      <td>0.004062</td>\n",
       "      <td>-0.004270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>some</th>\n",
       "      <td>-0.009579</td>\n",
       "      <td>0.008943</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.009235</td>\n",
       "      <td>0.006644</td>\n",
       "      <td>0.002925</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>-0.004425</td>\n",
       "      <td>-0.006803</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005085</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>-0.001536</td>\n",
       "      <td>0.009932</td>\n",
       "      <td>0.008350</td>\n",
       "      <td>0.002416</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>0.005891</td>\n",
       "      <td>-0.005581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This</th>\n",
       "      <td>-0.005157</td>\n",
       "      <td>-0.006668</td>\n",
       "      <td>-0.007777</td>\n",
       "      <td>0.008311</td>\n",
       "      <td>-0.001982</td>\n",
       "      <td>-0.006855</td>\n",
       "      <td>-0.004154</td>\n",
       "      <td>0.005144</td>\n",
       "      <td>-0.002869</td>\n",
       "      <td>-0.003750</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008977</td>\n",
       "      <td>0.008592</td>\n",
       "      <td>0.004047</td>\n",
       "      <td>0.007469</td>\n",
       "      <td>0.009746</td>\n",
       "      <td>-0.007290</td>\n",
       "      <td>-0.009040</td>\n",
       "      <td>0.005836</td>\n",
       "      <td>0.009391</td>\n",
       "      <td>0.003507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue</th>\n",
       "      <td>0.007088</td>\n",
       "      <td>-0.001568</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>-0.009489</td>\n",
       "      <td>-0.008029</td>\n",
       "      <td>-0.006641</td>\n",
       "      <td>-0.004004</td>\n",
       "      <td>0.004990</td>\n",
       "      <td>-0.003814</td>\n",
       "      <td>-0.008321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>-0.001265</td>\n",
       "      <td>0.005768</td>\n",
       "      <td>-0.005640</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.009458</td>\n",
       "      <td>-0.005482</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>-0.008113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>violet</th>\n",
       "      <td>0.009770</td>\n",
       "      <td>0.008165</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>0.005098</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>-0.006455</td>\n",
       "      <td>-0.001428</td>\n",
       "      <td>0.006449</td>\n",
       "      <td>-0.004617</td>\n",
       "      <td>-0.003993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004774</td>\n",
       "      <td>-0.003262</td>\n",
       "      <td>-0.009268</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.007161</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>-0.007865</td>\n",
       "      <td>-0.002973</td>\n",
       "      <td>-0.004932</td>\n",
       "      <td>-0.002315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red</th>\n",
       "      <td>-0.001944</td>\n",
       "      <td>-0.005268</td>\n",
       "      <td>0.009447</td>\n",
       "      <td>-0.009299</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>0.005404</td>\n",
       "      <td>-0.001409</td>\n",
       "      <td>0.009007</td>\n",
       "      <td>0.009885</td>\n",
       "      <td>-0.005475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>-0.002565</td>\n",
       "      <td>0.006448</td>\n",
       "      <td>-0.007660</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.008732</td>\n",
       "      <td>0.005983</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.007823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rose</th>\n",
       "      <td>-0.009500</td>\n",
       "      <td>0.009562</td>\n",
       "      <td>-0.007771</td>\n",
       "      <td>-0.002646</td>\n",
       "      <td>-0.004906</td>\n",
       "      <td>-0.004967</td>\n",
       "      <td>-0.008024</td>\n",
       "      <td>-0.007784</td>\n",
       "      <td>-0.004553</td>\n",
       "      <td>-0.001275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008380</td>\n",
       "      <td>0.007234</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>-0.001347</td>\n",
       "      <td>-0.005890</td>\n",
       "      <td>-0.004533</td>\n",
       "      <td>0.008648</td>\n",
       "      <td>-0.003135</td>\n",
       "      <td>-0.006339</td>\n",
       "      <td>0.009870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0         1         2         3         4         5   \\\n",
       "is            -0.000536  0.000237  0.005105  0.009009 -0.009303 -0.007118   \n",
       ".             -0.008620  0.003666  0.005190  0.005742  0.007467 -0.006168   \n",
       "The            0.000095  0.003077 -0.006813 -0.001375  0.007669  0.007346   \n",
       "demonstration -0.008243  0.009299 -0.000198 -0.001967  0.004604 -0.004095   \n",
       "for           -0.007139  0.001241 -0.007177 -0.002245  0.003719  0.005833   \n",
       "just          -0.008727  0.002130 -0.000874 -0.009319 -0.009428 -0.001411   \n",
       ",              0.008132 -0.004457 -0.001068  0.001006 -0.000191  0.001148   \n",
       "text           0.008168 -0.004443  0.008985  0.008254 -0.004435  0.000303   \n",
       "some          -0.009579  0.008943  0.004165  0.009235  0.006644  0.002925   \n",
       "This          -0.005157 -0.006668 -0.007777  0.008311 -0.001982 -0.006855   \n",
       "blue           0.007088 -0.001568  0.007949 -0.009489 -0.008029 -0.006641   \n",
       "violet         0.009770  0.008165  0.001281  0.005098  0.001408 -0.006455   \n",
       "red           -0.001944 -0.005268  0.009447 -0.009299  0.004504  0.005404   \n",
       "rose          -0.009500  0.009562 -0.007771 -0.002646 -0.004906 -0.004967   \n",
       "\n",
       "                     6         7         8         9   ...        90  \\\n",
       "is             0.006459  0.008974 -0.005016 -0.003765  ...  0.001632   \n",
       ".              0.001106  0.006047 -0.002840 -0.006174  ...  0.001088   \n",
       "The           -0.003673  0.002643 -0.008317  0.006205  ... -0.004509   \n",
       "demonstration  0.002743  0.006940  0.006065 -0.007511  ... -0.007426   \n",
       "for            0.001198  0.002103 -0.004110  0.007225  ...  0.003137   \n",
       "just           0.004432  0.003704 -0.006499 -0.006873  ...  0.009071   \n",
       ",              0.006114 -0.000020 -0.003246 -0.001511  ... -0.002701   \n",
       "text           0.004274 -0.003926 -0.005560 -0.006512  ...  0.002058   \n",
       "some           0.009804 -0.004425 -0.006803  0.004227  ... -0.005085   \n",
       "This          -0.004154  0.005144 -0.002869 -0.003750  ... -0.008977   \n",
       "blue          -0.004004  0.004990 -0.003814 -0.008321  ...  0.007513   \n",
       "violet        -0.001428  0.006449 -0.004617 -0.003993  ...  0.004774   \n",
       "red           -0.001409  0.009007  0.009885 -0.005475  ...  0.002651   \n",
       "rose          -0.008024 -0.007784 -0.004553 -0.001275  ...  0.008380   \n",
       "\n",
       "                     91        92        93        94        95        96  \\\n",
       "is             0.000190  0.003474  0.000218  0.009618  0.005061 -0.008916   \n",
       ".             -0.001576  0.002197 -0.007882 -0.002717  0.002663  0.005347   \n",
       "The            0.005702  0.009180 -0.004100  0.007965  0.005375  0.005879   \n",
       "demonstration -0.001064 -0.000795 -0.002563  0.009683 -0.000459  0.005874   \n",
       "for           -0.004713  0.005281 -0.004233  0.002642 -0.008046  0.006210   \n",
       "just           0.008938 -0.008208 -0.003012  0.009887  0.005104 -0.001588   \n",
       ",              0.000444 -0.003537 -0.000419 -0.000709  0.000823  0.008195   \n",
       "text          -0.004004 -0.008241  0.006278 -0.001949 -0.000666 -0.001771   \n",
       "some           0.001131  0.002883 -0.001536  0.009932  0.008350  0.002416   \n",
       "This           0.008592  0.004047  0.007469  0.009746 -0.007290 -0.009040   \n",
       "blue           0.001498 -0.001265  0.005768 -0.005640  0.000039  0.009458   \n",
       "violet        -0.003262 -0.009268  0.003787  0.007161 -0.005633 -0.007865   \n",
       "red           -0.002565  0.006448 -0.007660  0.003394  0.000490  0.008732   \n",
       "rose           0.007234  0.001730 -0.001347 -0.005890 -0.004533  0.008648   \n",
       "\n",
       "                     97        98        99  \n",
       "is            -0.007042  0.000901  0.006392  \n",
       ".             -0.002392 -0.009510  0.004506  \n",
       "The            0.000513  0.008213 -0.007019  \n",
       "demonstration -0.007448 -0.002506 -0.005550  \n",
       "for            0.004819  0.000787  0.003013  \n",
       "just          -0.008692  0.002962 -0.006676  \n",
       ",             -0.005737 -0.001660  0.005572  \n",
       "text          -0.004536  0.004062 -0.004270  \n",
       "some           0.007118  0.005891 -0.005581  \n",
       "This           0.005836  0.009391  0.003507  \n",
       "blue          -0.005482  0.003813 -0.008113  \n",
       "violet        -0.002973 -0.004932 -0.002315  \n",
       "red            0.005983  0.006815  0.007823  \n",
       "rose          -0.003135 -0.006339  0.009870  \n",
       "\n",
       "[14 rows x 100 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(wvs, index = words)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6cbba3",
   "metadata": {},
   "source": [
    "#### word2vec representation allows us to compute similarity in terms of cosine similarity metric between the word vectors in the embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b901ac51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 532
    },
    "id": "b901ac51",
    "outputId": "2c06c8b5-6b66-461b-c57b-9afe3bd3de76"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is</th>\n",
       "      <th>.</th>\n",
       "      <th>The</th>\n",
       "      <th>demonstration</th>\n",
       "      <th>for</th>\n",
       "      <th>just</th>\n",
       "      <th>,</th>\n",
       "      <th>text</th>\n",
       "      <th>some</th>\n",
       "      <th>This</th>\n",
       "      <th>blue</th>\n",
       "      <th>violet</th>\n",
       "      <th>red</th>\n",
       "      <th>rose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.010757</td>\n",
       "      <td>-0.052358</td>\n",
       "      <td>-0.111662</td>\n",
       "      <td>-0.027774</td>\n",
       "      <td>-0.059873</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.092916</td>\n",
       "      <td>0.027063</td>\n",
       "      <td>0.216162</td>\n",
       "      <td>0.062931</td>\n",
       "      <td>0.079646</td>\n",
       "      <td>0.093112</td>\n",
       "      <td>-0.041240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>-0.010757</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.023672</td>\n",
       "      <td>0.067976</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>0.009391</td>\n",
       "      <td>-0.114107</td>\n",
       "      <td>-0.115555</td>\n",
       "      <td>0.033641</td>\n",
       "      <td>-0.095716</td>\n",
       "      <td>-0.134190</td>\n",
       "      <td>0.008316</td>\n",
       "      <td>-0.003644</td>\n",
       "      <td>0.137253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The</th>\n",
       "      <td>-0.052358</td>\n",
       "      <td>-0.023672</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.013515</td>\n",
       "      <td>0.170189</td>\n",
       "      <td>0.064090</td>\n",
       "      <td>0.145951</td>\n",
       "      <td>-0.002754</td>\n",
       "      <td>0.199121</td>\n",
       "      <td>-0.032844</td>\n",
       "      <td>-0.101988</td>\n",
       "      <td>0.172728</td>\n",
       "      <td>0.046526</td>\n",
       "      <td>-0.135392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demonstration</th>\n",
       "      <td>-0.111662</td>\n",
       "      <td>0.067976</td>\n",
       "      <td>-0.013515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.044617</td>\n",
       "      <td>0.131490</td>\n",
       "      <td>0.041577</td>\n",
       "      <td>-0.013680</td>\n",
       "      <td>0.074976</td>\n",
       "      <td>-0.169368</td>\n",
       "      <td>0.012988</td>\n",
       "      <td>0.041308</td>\n",
       "      <td>-0.009253</td>\n",
       "      <td>0.006598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>-0.027774</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>0.170189</td>\n",
       "      <td>-0.044617</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.138880</td>\n",
       "      <td>0.034765</td>\n",
       "      <td>-0.028491</td>\n",
       "      <td>-0.069003</td>\n",
       "      <td>-0.173234</td>\n",
       "      <td>-0.258891</td>\n",
       "      <td>-0.005897</td>\n",
       "      <td>0.150165</td>\n",
       "      <td>0.252905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>-0.059873</td>\n",
       "      <td>0.009391</td>\n",
       "      <td>0.064090</td>\n",
       "      <td>0.131490</td>\n",
       "      <td>0.138880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019152</td>\n",
       "      <td>-0.057746</td>\n",
       "      <td>0.060592</td>\n",
       "      <td>-0.105138</td>\n",
       "      <td>0.020002</td>\n",
       "      <td>0.166947</td>\n",
       "      <td>-0.145108</td>\n",
       "      <td>0.044107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.016129</td>\n",
       "      <td>-0.114107</td>\n",
       "      <td>0.145951</td>\n",
       "      <td>0.041577</td>\n",
       "      <td>0.034765</td>\n",
       "      <td>0.019152</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004843</td>\n",
       "      <td>0.008826</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.050470</td>\n",
       "      <td>-0.083826</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.012812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>0.092916</td>\n",
       "      <td>-0.115555</td>\n",
       "      <td>-0.002754</td>\n",
       "      <td>-0.013680</td>\n",
       "      <td>-0.028491</td>\n",
       "      <td>-0.057746</td>\n",
       "      <td>0.004843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.144546</td>\n",
       "      <td>-0.093274</td>\n",
       "      <td>0.108879</td>\n",
       "      <td>0.111180</td>\n",
       "      <td>-0.040905</td>\n",
       "      <td>-0.025461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>some</th>\n",
       "      <td>0.027063</td>\n",
       "      <td>0.033641</td>\n",
       "      <td>0.199121</td>\n",
       "      <td>0.074976</td>\n",
       "      <td>-0.069003</td>\n",
       "      <td>0.060592</td>\n",
       "      <td>0.008826</td>\n",
       "      <td>-0.144546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044691</td>\n",
       "      <td>0.026811</td>\n",
       "      <td>0.037713</td>\n",
       "      <td>-0.040441</td>\n",
       "      <td>-0.122462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This</th>\n",
       "      <td>0.216162</td>\n",
       "      <td>-0.095716</td>\n",
       "      <td>-0.032844</td>\n",
       "      <td>-0.169368</td>\n",
       "      <td>-0.173234</td>\n",
       "      <td>-0.105138</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>-0.093274</td>\n",
       "      <td>0.044691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015009</td>\n",
       "      <td>-0.074243</td>\n",
       "      <td>-0.045690</td>\n",
       "      <td>-0.106194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue</th>\n",
       "      <td>0.062931</td>\n",
       "      <td>-0.134190</td>\n",
       "      <td>-0.101988</td>\n",
       "      <td>0.012988</td>\n",
       "      <td>-0.258891</td>\n",
       "      <td>0.020002</td>\n",
       "      <td>0.050470</td>\n",
       "      <td>0.108879</td>\n",
       "      <td>0.026811</td>\n",
       "      <td>0.015009</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.109421</td>\n",
       "      <td>0.128136</td>\n",
       "      <td>-0.001182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>violet</th>\n",
       "      <td>0.079646</td>\n",
       "      <td>0.008316</td>\n",
       "      <td>0.172728</td>\n",
       "      <td>0.041308</td>\n",
       "      <td>-0.005897</td>\n",
       "      <td>0.166947</td>\n",
       "      <td>-0.083826</td>\n",
       "      <td>0.111180</td>\n",
       "      <td>0.037713</td>\n",
       "      <td>-0.074243</td>\n",
       "      <td>0.109421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.030302</td>\n",
       "      <td>-0.162887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red</th>\n",
       "      <td>0.093112</td>\n",
       "      <td>-0.003644</td>\n",
       "      <td>0.046526</td>\n",
       "      <td>-0.009253</td>\n",
       "      <td>0.150165</td>\n",
       "      <td>-0.145108</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>-0.040905</td>\n",
       "      <td>-0.040441</td>\n",
       "      <td>-0.045690</td>\n",
       "      <td>0.128136</td>\n",
       "      <td>-0.030302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.076390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rose</th>\n",
       "      <td>-0.041240</td>\n",
       "      <td>0.137253</td>\n",
       "      <td>-0.135392</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.252905</td>\n",
       "      <td>0.044107</td>\n",
       "      <td>0.012812</td>\n",
       "      <td>-0.025461</td>\n",
       "      <td>-0.122462</td>\n",
       "      <td>-0.106194</td>\n",
       "      <td>-0.001182</td>\n",
       "      <td>-0.162887</td>\n",
       "      <td>-0.076390</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     is         .       The  demonstration       for  \\\n",
       "is             1.000000 -0.010757 -0.052358      -0.111662 -0.027774   \n",
       ".             -0.010757  1.000000 -0.023672       0.067976  0.004503   \n",
       "The           -0.052358 -0.023672  1.000000      -0.013515  0.170189   \n",
       "demonstration -0.111662  0.067976 -0.013515       1.000000 -0.044617   \n",
       "for           -0.027774  0.004503  0.170189      -0.044617  1.000000   \n",
       "just          -0.059873  0.009391  0.064090       0.131490  0.138880   \n",
       ",              0.016129 -0.114107  0.145951       0.041577  0.034765   \n",
       "text           0.092916 -0.115555 -0.002754      -0.013680 -0.028491   \n",
       "some           0.027063  0.033641  0.199121       0.074976 -0.069003   \n",
       "This           0.216162 -0.095716 -0.032844      -0.169368 -0.173234   \n",
       "blue           0.062931 -0.134190 -0.101988       0.012988 -0.258891   \n",
       "violet         0.079646  0.008316  0.172728       0.041308 -0.005897   \n",
       "red            0.093112 -0.003644  0.046526      -0.009253  0.150165   \n",
       "rose          -0.041240  0.137253 -0.135392       0.006598  0.252905   \n",
       "\n",
       "                   just         ,      text      some      This      blue  \\\n",
       "is            -0.059873  0.016129  0.092916  0.027063  0.216162  0.062931   \n",
       ".              0.009391 -0.114107 -0.115555  0.033641 -0.095716 -0.134190   \n",
       "The            0.064090  0.145951 -0.002754  0.199121 -0.032844 -0.101988   \n",
       "demonstration  0.131490  0.041577 -0.013680  0.074976 -0.169368  0.012988   \n",
       "for            0.138880  0.034765 -0.028491 -0.069003 -0.173234 -0.258891   \n",
       "just           1.000000  0.019152 -0.057746  0.060592 -0.105138  0.020002   \n",
       ",              0.019152  1.000000  0.004843  0.008826  0.001947  0.050470   \n",
       "text          -0.057746  0.004843  1.000000 -0.144546 -0.093274  0.108879   \n",
       "some           0.060592  0.008826 -0.144546  1.000000  0.044691  0.026811   \n",
       "This          -0.105138  0.001947 -0.093274  0.044691  1.000000  0.015009   \n",
       "blue           0.020002  0.050470  0.108879  0.026811  0.015009  1.000000   \n",
       "violet         0.166947 -0.083826  0.111180  0.037713 -0.074243  0.109421   \n",
       "red           -0.145108  0.000731 -0.040905 -0.040441 -0.045690  0.128136   \n",
       "rose           0.044107  0.012812 -0.025461 -0.122462 -0.106194 -0.001182   \n",
       "\n",
       "                 violet       red      rose  \n",
       "is             0.079646  0.093112 -0.041240  \n",
       ".              0.008316 -0.003644  0.137253  \n",
       "The            0.172728  0.046526 -0.135392  \n",
       "demonstration  0.041308 -0.009253  0.006598  \n",
       "for           -0.005897  0.150165  0.252905  \n",
       "just           0.166947 -0.145108  0.044107  \n",
       ",             -0.083826  0.000731  0.012812  \n",
       "text           0.111180 -0.040905 -0.025461  \n",
       "some           0.037713 -0.040441 -0.122462  \n",
       "This          -0.074243 -0.045690 -0.106194  \n",
       "blue           0.109421  0.128136 -0.001182  \n",
       "violet         1.000000 -0.030302 -0.162887  \n",
       "red           -0.030302  1.000000 -0.076390  \n",
       "rose          -0.162887 -0.076390  1.000000  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Similarity Matrix\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_matrix = cosine_similarity(df.values)\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=words, columns=words)\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baea0a8",
   "metadata": {},
   "source": [
    "#### Visualizing the data points and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e00ecd5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "id": "6e00ecd5",
    "outputId": "d2a795b0-e2fb-4cdd-e8b4-c5ba307ccbf8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing the data points and embeddings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "words = wordtovector.wv.index_to_key\n",
    "wvs = wordtovector.wv[words]\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, n_iter=250, perplexity=5)\n",
    "tsne_model = tsne.fit_transform(wvs)\n",
    "labels = words\n",
    "\n",
    "plt.figure(figsize=(11, 8))\n",
    "plt.scatter(tsne_model[:, 0], tsne_model[:, 1])\n",
    "\n",
    "for label, x, y in zip(labels, tsne_model[:, 0], tsne_model[:, 1]):\n",
    "    plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), textcoords='offset points')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab2b877",
   "metadata": {
    "id": "aab2b877"
   },
   "source": [
    "### GloVe\n",
    "- Global Vectors (GloVe) also generates dense word vectors like Word2Vec. \n",
    "\n",
    "- GloVe model first creates a huge word-context co-occurrence matrix consisting of (word, context) pairs such that each element in this matrix represents how often a word occurs with the context (which can be a sequence of words). Then matrix factorization can be applied to approximate this matrix.\n",
    "\n",
    "- It is trained on an aggregated global word-word co-occurrence matrix, giving us a vector space with meaningful sub-structures. \n",
    "\n",
    "- The Spacy library has support for GloVe embeddings. \n",
    "- For using English language embeddings we need to download the pipeline \"en_core_web_lg\", the large English language pipeline.   We get the standard 300-dimensional GloVe word vectors using SpaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "_hiy0bm4AAYk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_hiy0bm4AAYk",
    "outputId": "0bf3a5b9-5b32-4877-95e2-498a10db117b"
   },
   "outputs": [],
   "source": [
    "#!spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3d6798e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "3d6798e9",
    "outputId": "e444f632-210f-4cbd-ad31-3ac5a8dfb023"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word vectors: 514157\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>1.815300</td>\n",
       "      <td>-3.09740</td>\n",
       "      <td>7.87810</td>\n",
       "      <td>1.71590</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-4.63070</td>\n",
       "      <td>3.67090</td>\n",
       "      <td>-0.085784</td>\n",
       "      <td>-4.97550</td>\n",
       "      <td>-0.840940</td>\n",
       "      <td>...</td>\n",
       "      <td>3.79580</td>\n",
       "      <td>-0.61199</td>\n",
       "      <td>4.80440</td>\n",
       "      <td>-3.927300</td>\n",
       "      <td>-0.13952</td>\n",
       "      <td>1.68680</td>\n",
       "      <td>5.259600</td>\n",
       "      <td>-4.02700</td>\n",
       "      <td>-4.81260</td>\n",
       "      <td>-1.845800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>1.475000</td>\n",
       "      <td>6.00780</td>\n",
       "      <td>1.12050</td>\n",
       "      <td>-3.58740</td>\n",
       "      <td>3.76380</td>\n",
       "      <td>3.19870</td>\n",
       "      <td>-2.20600</td>\n",
       "      <td>3.212800</td>\n",
       "      <td>-2.08160</td>\n",
       "      <td>-0.002931</td>\n",
       "      <td>...</td>\n",
       "      <td>10.95500</td>\n",
       "      <td>-2.96190</td>\n",
       "      <td>4.54070</td>\n",
       "      <td>-2.299900</td>\n",
       "      <td>-0.99536</td>\n",
       "      <td>1.26190</td>\n",
       "      <td>-2.332600</td>\n",
       "      <td>-0.22893</td>\n",
       "      <td>-0.85967</td>\n",
       "      <td>9.746600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red</th>\n",
       "      <td>-6.987800</td>\n",
       "      <td>1.16150</td>\n",
       "      <td>-8.06920</td>\n",
       "      <td>7.80010</td>\n",
       "      <td>1.52120</td>\n",
       "      <td>-7.22220</td>\n",
       "      <td>-2.06460</td>\n",
       "      <td>1.894000</td>\n",
       "      <td>2.36250</td>\n",
       "      <td>2.690200</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.82510</td>\n",
       "      <td>4.03390</td>\n",
       "      <td>5.65330</td>\n",
       "      <td>-3.860400</td>\n",
       "      <td>-0.72858</td>\n",
       "      <td>6.38290</td>\n",
       "      <td>6.829400</td>\n",
       "      <td>-0.30026</td>\n",
       "      <td>-3.95430</td>\n",
       "      <td>-2.621500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>-7.078100</td>\n",
       "      <td>-2.68880</td>\n",
       "      <td>-4.08680</td>\n",
       "      <td>0.42781</td>\n",
       "      <td>6.61630</td>\n",
       "      <td>-0.29513</td>\n",
       "      <td>-2.29380</td>\n",
       "      <td>6.523300</td>\n",
       "      <td>-0.13721</td>\n",
       "      <td>-1.193800</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.42070</td>\n",
       "      <td>-4.35240</td>\n",
       "      <td>-1.82680</td>\n",
       "      <td>-0.069293</td>\n",
       "      <td>-2.15780</td>\n",
       "      <td>-0.40668</td>\n",
       "      <td>-3.475100</td>\n",
       "      <td>-1.06450</td>\n",
       "      <td>-5.53650</td>\n",
       "      <td>2.474600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This</th>\n",
       "      <td>1.684900</td>\n",
       "      <td>1.98260</td>\n",
       "      <td>-0.77743</td>\n",
       "      <td>-4.73830</td>\n",
       "      <td>5.54180</td>\n",
       "      <td>-1.62260</td>\n",
       "      <td>6.29550</td>\n",
       "      <td>0.227450</td>\n",
       "      <td>0.31281</td>\n",
       "      <td>-3.149400</td>\n",
       "      <td>...</td>\n",
       "      <td>3.28310</td>\n",
       "      <td>4.03420</td>\n",
       "      <td>9.90010</td>\n",
       "      <td>2.544900</td>\n",
       "      <td>-0.10740</td>\n",
       "      <td>6.52750</td>\n",
       "      <td>1.826900</td>\n",
       "      <td>-1.82890</td>\n",
       "      <td>-2.94540</td>\n",
       "      <td>-0.833370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>-0.076454</td>\n",
       "      <td>-4.68960</td>\n",
       "      <td>-4.04310</td>\n",
       "      <td>-3.43330</td>\n",
       "      <td>11.75800</td>\n",
       "      <td>3.72120</td>\n",
       "      <td>-0.98133</td>\n",
       "      <td>2.790200</td>\n",
       "      <td>0.43608</td>\n",
       "      <td>-2.442500</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.77490</td>\n",
       "      <td>3.01470</td>\n",
       "      <td>1.86150</td>\n",
       "      <td>-3.955600</td>\n",
       "      <td>1.13400</td>\n",
       "      <td>3.02430</td>\n",
       "      <td>-3.098400</td>\n",
       "      <td>1.30400</td>\n",
       "      <td>-0.52699</td>\n",
       "      <td>-1.362200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>some</th>\n",
       "      <td>-0.911380</td>\n",
       "      <td>-1.24670</td>\n",
       "      <td>-1.44040</td>\n",
       "      <td>3.22800</td>\n",
       "      <td>-1.50450</td>\n",
       "      <td>-2.27990</td>\n",
       "      <td>0.37714</td>\n",
       "      <td>7.836300</td>\n",
       "      <td>-5.41800</td>\n",
       "      <td>-1.961900</td>\n",
       "      <td>...</td>\n",
       "      <td>3.18080</td>\n",
       "      <td>-7.12370</td>\n",
       "      <td>2.64700</td>\n",
       "      <td>1.721400</td>\n",
       "      <td>-3.33810</td>\n",
       "      <td>1.82060</td>\n",
       "      <td>-0.863030</td>\n",
       "      <td>-1.13780</td>\n",
       "      <td>-6.43880</td>\n",
       "      <td>3.759900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-3.389900</td>\n",
       "      <td>-4.70340</td>\n",
       "      <td>-0.56101</td>\n",
       "      <td>1.22910</td>\n",
       "      <td>4.32980</td>\n",
       "      <td>-1.07750</td>\n",
       "      <td>-1.30060</td>\n",
       "      <td>8.793900</td>\n",
       "      <td>-0.16669</td>\n",
       "      <td>-4.373800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13658</td>\n",
       "      <td>-3.62980</td>\n",
       "      <td>-2.65040</td>\n",
       "      <td>-5.227000</td>\n",
       "      <td>-2.77310</td>\n",
       "      <td>3.16950</td>\n",
       "      <td>2.779600</td>\n",
       "      <td>0.73668</td>\n",
       "      <td>-0.62700</td>\n",
       "      <td>0.071074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rose</th>\n",
       "      <td>-0.945060</td>\n",
       "      <td>-6.83510</td>\n",
       "      <td>-2.48310</td>\n",
       "      <td>1.06740</td>\n",
       "      <td>1.62590</td>\n",
       "      <td>-4.94570</td>\n",
       "      <td>-1.15260</td>\n",
       "      <td>7.013700</td>\n",
       "      <td>4.24760</td>\n",
       "      <td>1.426400</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.15790</td>\n",
       "      <td>7.33210</td>\n",
       "      <td>-3.83220</td>\n",
       "      <td>-4.016000</td>\n",
       "      <td>1.13540</td>\n",
       "      <td>2.96460</td>\n",
       "      <td>3.281000</td>\n",
       "      <td>3.43790</td>\n",
       "      <td>-1.01020</td>\n",
       "      <td>-3.266100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The</th>\n",
       "      <td>-7.268100</td>\n",
       "      <td>-0.85717</td>\n",
       "      <td>5.81050</td>\n",
       "      <td>1.97710</td>\n",
       "      <td>8.81470</td>\n",
       "      <td>-5.85790</td>\n",
       "      <td>3.71430</td>\n",
       "      <td>3.585000</td>\n",
       "      <td>4.79870</td>\n",
       "      <td>-4.425100</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.23500</td>\n",
       "      <td>1.62090</td>\n",
       "      <td>7.89940</td>\n",
       "      <td>10.741000</td>\n",
       "      <td>0.81158</td>\n",
       "      <td>9.01560</td>\n",
       "      <td>-1.591300</td>\n",
       "      <td>-5.31660</td>\n",
       "      <td>0.35032</td>\n",
       "      <td>-2.885000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demonstration</th>\n",
       "      <td>-2.042900</td>\n",
       "      <td>-2.43160</td>\n",
       "      <td>-0.90118</td>\n",
       "      <td>2.68980</td>\n",
       "      <td>3.24890</td>\n",
       "      <td>-0.57169</td>\n",
       "      <td>2.25440</td>\n",
       "      <td>2.664000</td>\n",
       "      <td>-2.63810</td>\n",
       "      <td>-1.605100</td>\n",
       "      <td>...</td>\n",
       "      <td>1.07060</td>\n",
       "      <td>-0.26622</td>\n",
       "      <td>-0.23884</td>\n",
       "      <td>0.947490</td>\n",
       "      <td>0.57047</td>\n",
       "      <td>0.45281</td>\n",
       "      <td>2.014900</td>\n",
       "      <td>-3.82190</td>\n",
       "      <td>-2.93230</td>\n",
       "      <td>-0.584160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue</th>\n",
       "      <td>-4.310200</td>\n",
       "      <td>2.57060</td>\n",
       "      <td>-3.47220</td>\n",
       "      <td>2.52050</td>\n",
       "      <td>-1.11040</td>\n",
       "      <td>-5.10140</td>\n",
       "      <td>-1.48120</td>\n",
       "      <td>4.655900</td>\n",
       "      <td>0.38365</td>\n",
       "      <td>2.477200</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.25050</td>\n",
       "      <td>4.20530</td>\n",
       "      <td>2.92490</td>\n",
       "      <td>-0.933100</td>\n",
       "      <td>0.89071</td>\n",
       "      <td>6.85240</td>\n",
       "      <td>0.075678</td>\n",
       "      <td>1.07370</td>\n",
       "      <td>-2.96000</td>\n",
       "      <td>-0.422090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>violet</th>\n",
       "      <td>0.686350</td>\n",
       "      <td>0.52593</td>\n",
       "      <td>-4.45120</td>\n",
       "      <td>-0.23707</td>\n",
       "      <td>0.19831</td>\n",
       "      <td>-0.98637</td>\n",
       "      <td>1.85220</td>\n",
       "      <td>2.126800</td>\n",
       "      <td>-0.16475</td>\n",
       "      <td>1.911000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.77459</td>\n",
       "      <td>1.90150</td>\n",
       "      <td>0.60018</td>\n",
       "      <td>-3.327600</td>\n",
       "      <td>0.19464</td>\n",
       "      <td>-0.37326</td>\n",
       "      <td>3.051700</td>\n",
       "      <td>0.89647</td>\n",
       "      <td>-3.07600</td>\n",
       "      <td>0.793250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>-1.964800</td>\n",
       "      <td>3.05660</td>\n",
       "      <td>-3.10230</td>\n",
       "      <td>-1.73530</td>\n",
       "      <td>-1.18430</td>\n",
       "      <td>1.64040</td>\n",
       "      <td>2.78360</td>\n",
       "      <td>3.443900</td>\n",
       "      <td>-3.25980</td>\n",
       "      <td>2.925100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.87217</td>\n",
       "      <td>-0.48226</td>\n",
       "      <td>3.24620</td>\n",
       "      <td>-2.112300</td>\n",
       "      <td>-5.00440</td>\n",
       "      <td>1.69560</td>\n",
       "      <td>3.613800</td>\n",
       "      <td>4.83060</td>\n",
       "      <td>-4.37310</td>\n",
       "      <td>0.653810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0        1        2        3         4        5    \\\n",
       "text           1.815300 -3.09740  7.87810  1.71590   1.34920 -4.63070   \n",
       "is             1.475000  6.00780  1.12050 -3.58740   3.76380  3.19870   \n",
       "red           -6.987800  1.16150 -8.06920  7.80010   1.52120 -7.22220   \n",
       "for           -7.078100 -2.68880 -4.08680  0.42781   6.61630 -0.29513   \n",
       "This           1.684900  1.98260 -0.77743 -4.73830   5.54180 -1.62260   \n",
       ".             -0.076454 -4.68960 -4.04310 -3.43330  11.75800  3.72120   \n",
       "some          -0.911380 -1.24670 -1.44040  3.22800  -1.50450 -2.27990   \n",
       ",             -3.389900 -4.70340 -0.56101  1.22910   4.32980 -1.07750   \n",
       "rose          -0.945060 -6.83510 -2.48310  1.06740   1.62590 -4.94570   \n",
       "The           -7.268100 -0.85717  5.81050  1.97710   8.81470 -5.85790   \n",
       "demonstration -2.042900 -2.43160 -0.90118  2.68980   3.24890 -0.57169   \n",
       "blue          -4.310200  2.57060 -3.47220  2.52050  -1.11040 -5.10140   \n",
       "violet         0.686350  0.52593 -4.45120 -0.23707   0.19831 -0.98637   \n",
       "just          -1.964800  3.05660 -3.10230 -1.73530  -1.18430  1.64040   \n",
       "\n",
       "                   6         7        8         9    ...       290      291  \\\n",
       "text           3.67090 -0.085784 -4.97550 -0.840940  ...   3.79580 -0.61199   \n",
       "is            -2.20600  3.212800 -2.08160 -0.002931  ...  10.95500 -2.96190   \n",
       "red           -2.06460  1.894000  2.36250  2.690200  ...  -1.82510  4.03390   \n",
       "for           -2.29380  6.523300 -0.13721 -1.193800  ...  -3.42070 -4.35240   \n",
       "This           6.29550  0.227450  0.31281 -3.149400  ...   3.28310  4.03420   \n",
       ".             -0.98133  2.790200  0.43608 -2.442500  ...  -3.77490  3.01470   \n",
       "some           0.37714  7.836300 -5.41800 -1.961900  ...   3.18080 -7.12370   \n",
       ",             -1.30060  8.793900 -0.16669 -4.373800  ...   0.13658 -3.62980   \n",
       "rose          -1.15260  7.013700  4.24760  1.426400  ...  -1.15790  7.33210   \n",
       "The            3.71430  3.585000  4.79870 -4.425100  ...  -1.23500  1.62090   \n",
       "demonstration  2.25440  2.664000 -2.63810 -1.605100  ...   1.07060 -0.26622   \n",
       "blue          -1.48120  4.655900  0.38365  2.477200  ...  -5.25050  4.20530   \n",
       "violet         1.85220  2.126800 -0.16475  1.911000  ...   0.77459  1.90150   \n",
       "just           2.78360  3.443900 -3.25980  2.925100  ...   0.87217 -0.48226   \n",
       "\n",
       "                   292        293      294      295       296      297  \\\n",
       "text           4.80440  -3.927300 -0.13952  1.68680  5.259600 -4.02700   \n",
       "is             4.54070  -2.299900 -0.99536  1.26190 -2.332600 -0.22893   \n",
       "red            5.65330  -3.860400 -0.72858  6.38290  6.829400 -0.30026   \n",
       "for           -1.82680  -0.069293 -2.15780 -0.40668 -3.475100 -1.06450   \n",
       "This           9.90010   2.544900 -0.10740  6.52750  1.826900 -1.82890   \n",
       ".              1.86150  -3.955600  1.13400  3.02430 -3.098400  1.30400   \n",
       "some           2.64700   1.721400 -3.33810  1.82060 -0.863030 -1.13780   \n",
       ",             -2.65040  -5.227000 -2.77310  3.16950  2.779600  0.73668   \n",
       "rose          -3.83220  -4.016000  1.13540  2.96460  3.281000  3.43790   \n",
       "The            7.89940  10.741000  0.81158  9.01560 -1.591300 -5.31660   \n",
       "demonstration -0.23884   0.947490  0.57047  0.45281  2.014900 -3.82190   \n",
       "blue           2.92490  -0.933100  0.89071  6.85240  0.075678  1.07370   \n",
       "violet         0.60018  -3.327600  0.19464 -0.37326  3.051700  0.89647   \n",
       "just           3.24620  -2.112300 -5.00440  1.69560  3.613800  4.83060   \n",
       "\n",
       "                   298       299  \n",
       "text          -4.81260 -1.845800  \n",
       "is            -0.85967  9.746600  \n",
       "red           -3.95430 -2.621500  \n",
       "for           -5.53650  2.474600  \n",
       "This          -2.94540 -0.833370  \n",
       ".             -0.52699 -1.362200  \n",
       "some          -6.43880  3.759900  \n",
       ",             -0.62700  0.071074  \n",
       "rose          -1.01020 -3.266100  \n",
       "The            0.35032 -2.885000  \n",
       "demonstration -2.93230 -0.584160  \n",
       "blue          -2.96000 -0.422090  \n",
       "violet        -3.07600  0.793250  \n",
       "just          -4.37310  0.653810  \n",
       "\n",
       "[14 rows x 300 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "total_vectors = len(nlp.vocab.vectors)\n",
    "print('Total word vectors:', total_vectors)\n",
    "\n",
    "document = [\"The rose is red.\", \"The violet is blue.\", \"This is some text, just for demonstration\"]\n",
    "tokenized_corpus = [nltk.word_tokenize(doc) for doc in document]\n",
    "\n",
    "vocab = list(set([word for wordlist in tokenized_corpus for word in wordlist]))\n",
    "\n",
    "glovevectors = np.array([nlp(word).vector for word in vocab])#Spacy's nlp pipeline has the vectors for these words\n",
    "glove_vec_df = pd.DataFrame(glovevectors, index=vocab)\n",
    "glove_vec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e3d82423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.68635\n",
       "1      0.52593\n",
       "2     -4.45120\n",
       "3     -0.23707\n",
       "4      0.19831\n",
       "        ...   \n",
       "295   -0.37326\n",
       "296    3.05170\n",
       "297    0.89647\n",
       "298   -3.07600\n",
       "299    0.79325\n",
       "Name: violet, Length: 300, dtype: float32"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vec_df.loc['violet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "14b8367c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.8153 , -3.0974 ,  7.8781 , ..., -4.027  , -4.8126 , -1.8458 ],\n",
       "       [ 1.475  ,  6.0078 ,  1.1205 , ..., -0.22893, -0.85967,  9.7466 ],\n",
       "       [-6.9878 ,  1.1615 , -8.0692 , ..., -0.30026, -3.9543 , -2.6215 ],\n",
       "       ...,\n",
       "       [-4.3102 ,  2.5706 , -3.4722 , ...,  1.0737 , -2.96   , -0.42209],\n",
       "       [ 0.68635,  0.52593, -4.4512 , ...,  0.89647, -3.076  ,  0.79325],\n",
       "       [-1.9648 ,  3.0566 , -3.1023 , ...,  4.8306 , -4.3731 ,  0.65381]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glovevectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "94924426",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "94924426",
    "outputId": "e1f99497-8e2c-40ad-d746-874faa1f95aa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing the data points\n",
    "tsne = TSNE(n_components = 2, random_state = 42, n_iter = 250, perplexity = 3)\n",
    "\n",
    "tsneglovemodel = tsne.fit_transform(glovevectors)\n",
    "labels = vocab\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(tsneglovemodel[:, 0], tsneglovemodel[:, 1], c='red', edgecolors='r')\n",
    "\n",
    "for label, x, y in zip(labels, tsneglovemodel[:, 0], tsneglovemodel[:, 1]):\n",
    "    plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), textcoords='offset points')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ded49b",
   "metadata": {
    "id": "03ded49b"
   },
   "source": [
    "#### FastText\n",
    "\n",
    "FastText is trained on Wikipedia and Common Crawl. It contains word vectors for 157 languages trained on Wikipedia and Crawl. It also contains models for language identification and various supervised tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0eb4de4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0eb4de4c",
    "outputId": "34e6c12d-ce48-4c22-f077-4b4519261e45"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from gensim.models.fasttext import FastText\n",
    "import nltk\n",
    "document = [\"The rose is red.\", \"The violet is blue.\", \"This is some text, just for demonstration\"]\n",
    "tokenized_corpus = [nltk.word_tokenize(doc) for doc in document]\n",
    "\n",
    "fasttext_model = FastText(tokenized_corpus, window = 5, min_count = 1, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "160e77fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding\n",
      "[-6.86851796e-04 -3.69698345e-03 -3.18645791e-04 -4.16084367e-04\n",
      "  9.21203056e-04  1.84563210e-03 -9.76437121e-04 -7.15407310e-04\n",
      " -1.54884940e-03 -2.82399007e-03 -2.92088574e-04  7.39330950e-04\n",
      " -1.80981262e-03  1.00511231e-03  1.36429898e-03 -2.61378498e-03\n",
      "  7.03200756e-04  5.70815231e-04  2.45103776e-03  8.12316939e-05\n",
      " -2.80409557e-04 -6.23123487e-04 -2.01529780e-04 -4.24301391e-03\n",
      " -8.33354541e-04  1.44310028e-03 -2.57517421e-03  8.56816245e-04\n",
      " -1.06297877e-04  2.33496120e-03  3.24346387e-04  2.07992620e-03\n",
      "  3.79742845e-03  3.08871065e-04  1.54514873e-05 -4.94979089e-04\n",
      "  1.26407191e-03  7.78723683e-04 -3.20366607e-03  4.52133565e-04\n",
      "  2.04523429e-04 -1.15022995e-04  1.48812062e-04  2.21455516e-03\n",
      " -1.13050989e-03 -2.62380089e-03 -2.11392739e-03 -1.26644713e-03\n",
      " -8.65892449e-04  2.44596461e-03  1.39622984e-03 -4.40237997e-03\n",
      " -4.07756976e-04 -1.40522985e-04 -8.44394031e-04 -2.57530686e-04\n",
      " -2.20658403e-04  3.42256913e-04  9.48390982e-04  3.08589981e-04\n",
      " -2.06774799e-03 -3.11020005e-04  2.49080430e-03  4.84697957e-05\n",
      "  2.21290407e-04  8.77263257e-04 -2.62321928e-03 -1.95961096e-03\n",
      " -1.28066470e-03 -1.38765050e-03  1.69619557e-03  1.98707497e-03\n",
      " -1.15068362e-03  4.73180786e-04  1.14016619e-03  5.95243589e-04\n",
      " -2.34133640e-05  1.02129055e-03 -6.53693778e-03 -4.94894979e-04\n",
      "  1.19589572e-03 -3.12033668e-03 -2.01747543e-03  9.23953252e-04\n",
      " -1.66515855e-03 -1.43948462e-04  2.31980532e-03 -5.03190269e-04\n",
      " -1.56434847e-03  3.42069729e-03  9.37537057e-04  9.82324360e-04\n",
      "  5.32097416e-03 -2.48571462e-03 -1.40935462e-03  3.92759638e-03\n",
      "  1.38463126e-03  2.69739423e-03 -1.02921948e-03 -5.36077656e-04]\n",
      "Embedding Shape\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print('Embedding')\n",
    "print(fasttext_model.wv['blue'])\n",
    "\n",
    "print('Embedding Shape')\n",
    "print(fasttext_model.wv['blue'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "265625d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.8048707e-04,  2.3094022e-03,  9.7770512e-04, ...,\n",
       "        -2.6284247e-03,  1.3848465e-03,  2.2230536e-04],\n",
       "       [-5.4783002e-03,  5.3737699e-03,  8.8895462e-04, ...,\n",
       "        -4.1347733e-03, -4.1223927e-03,  8.9752174e-04],\n",
       "       [ 1.1352475e-03,  2.5943687e-04,  2.6888266e-04, ...,\n",
       "         8.0563541e-04,  3.2540935e-03, -2.1021194e-03],\n",
       "       ...,\n",
       "       [ 5.5622414e-04,  3.1627396e-03,  7.4936973e-04, ...,\n",
       "        -1.1334260e-03, -1.1297673e-03,  1.0074716e-03],\n",
       "       [ 3.4134349e-04, -3.3717903e-03, -6.7485648e-04, ...,\n",
       "        -1.9201137e-04, -1.0929658e-03,  5.5667944e-05],\n",
       "       [-8.0672093e-04,  1.6167432e-03,  8.1310915e-05, ...,\n",
       "         4.1106177e-04, -2.0853011e-03,  2.3860238e-03]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_fasttext = fasttext_model.wv.index_to_key\n",
    "wordvectors_fasttext = fasttext_model.wv[words]\n",
    "wordvectors_fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6b9131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
